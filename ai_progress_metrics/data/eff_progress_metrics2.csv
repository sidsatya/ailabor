FeltenDim,Problem,Subproblem,Dataset,Title,Metric,Date,Algorithm,Metric Performance,Source
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2011-07-01,An Analysis of Single-Layer Networks in Unsupervised Feature Learning,79.6,An Analysis of Single-Layer Networks in Unsupervised Feature Learning
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2011-07-01,Hierarchical Kernel Descriptors,80,Object Recognition with Hierarchical Kernel Descriptors
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2012-06-16,MCDNN,88.79,Multi-Column Deep Neural Networks for Image Classification
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2012-06-26,Local Transformations,82.2,Learning Invariant Representations with Local Transformations
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2012-07-03,Improving neural networks by preventing co-adaptation of feature detectors,84.4,Improving neural networks by preventing co-adaptation of feature detectors
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2012-12-03,Learning with Recursive Perceptual Representations,79.7,Learning with Recursive Perceptual Representations
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2012-12-03,Discriminative Learning of Sum-Product Networks,83.96,Discriminative Learning of Sum-Product Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2012-12-03,DCNN,89,ImageNet Classification with Deep Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2012-12-03,GP EI,90.5,Practical Bayesian Optimization of Machine Learning Algorithms
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2013-01-16,Stochastic Pooling,84.87,Stochastic Pooling for Regularization of Deep Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2013-06-16,Maxout Networks,90.65,Maxout Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2013-06-16,DropConnect,90.68,Regularization of Neural Networks using DropConnect
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2013-07-01,Smooth Pooling Regions,80.02,Learning Smooth Pooling Regions for Visual Recognition
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-04-14,DNN+Probabilistic Maxout,90.61,Improving Deep Neural Networks with Probabilistic Maxout Units
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-04-14,NiN,91.2,Network In Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-06-21,PCANet,78.67,PCANet: A Simple Deep Learning Baseline for Image Classification?
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-06-21,Nonnegativity Constraints,82.9,Stable and Efficient Representation Learning with Nonnegativity Constraints
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-07-01,DSN,91.78,Deeply-Supervised Nets
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-08-28,CKN,82.18,Convolutional Kernel Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-09-22,SSCNN,93.72,Spatially-sparse convolutional neural networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-12-08,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks,82,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2014-12-08,Deep Networks with Internal Selective Attention through Feedback Connections,90.78,Deep Networks with Internal Selective Attention through Feedback Connections
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-02-13,An Analysis of Unsupervised Pre-training in Light of Recent Advances,86.7,An Analysis of Unsupervised Pre-training in Light of Recent Advances
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-02-15,ACN,95.59,Striving for Simplicity: The All Convolutional Net
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-02-19,NiN+APL,92.49,Learning Activation Functions to Improve Deep Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-02-28,Fractional MP,96.53,Fractional Max-Pooling
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-05-02,Tuned CNN,93.63,Scalable Bayesian Optimization Using Deep Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-05-13,APAC,89.67,APAC: Augmented PAttern Classification with Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-05-31,FLSCNN,75.86,Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-06-08,RCNN-96,92.91,Recurrent Convolutional Neural Network for Object Recognition
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-06-12,ReNet,87.65,ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-07-01,ELC,91.19,Speeding up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-07-01,MLR DNN,91.88,Multi-Loss Regularized Deep Neural Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-07-01,cifar.torch,92.45,cifar.torch
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-07-12,DCNN+GFE,89.14,Deep Convolutional Neural Networks as Generic Feature Extractors
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-08-16,RReLU,88.8,Empirical Evaluation of Rectified Activations in Convolution Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-09-17,MIM,91.48,On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-10-05,Tree+Max-Avg pooling,93.95,"Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree"
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-10-11,SWWAE,92.23,Stacked What-Where Auto-encoders
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-11-09,BNM NiN,93.25,Batch-normalized Maxout Network in Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-11-18,CMsC,93.13,Competitive Multi-scale Convolution
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-12-07,Spectral Representations for Convolutional Neural Networks,91.4,Spectral Representations for Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-12-07,BinaryConnect,91.73,BinaryConnect: Training Deep Neural Networks with binary weights during propagations
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-12-07,VDN,92.4,Training Very Deep Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2015-12-10,DRL,93.57,Deep Residual Learning for Image Recognition
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2016-01-04,Fitnet4-LSUV,94.16,All you need is a good init
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2016-01-07,Exponential Linear Units,93.45,Fast and Accurate Deep Network Learning by Exponential Linear Units
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2016-05-15,Universum Prescription,93.34,Universum Prescription: Regularization using Unlabeled Data
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2016-05-20,ResNet-1001,95.38,Identity Mappings in Deep Residual Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2016-07-10,ResNet+ELU,94.38,Deep Residual Networks with Exponential Linear Unit
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2017-02-15,Neural Architecture Search,96.35,Neural Architecture Search with Reinforcement Learning
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2017-04-22,Evolution,94.6,Large-Scale Evolution of Image Classifiers
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2017-04-22,Evolution ensemble,95.6,Large-Scale Evolution of Image Classifiers
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2017-05-30,Deep Complex,94.4,Deep Complex Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-10 Image Recognition,Percentage Correct,2017-07-16,RL+NT,94.6,Reinforcement Learning for Architecture Search by Network Transformation
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2012-06-16,Receptive Field Learning,54.23,Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2013-01-16,Stochastic Pooling,57.49,Stochastic Pooling for Regularization of Deep Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2013-06-16,Maxout Networks,61.43,Maxout Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2013-07-01,Smooth Pooling Regions,56.29,Smooth Pooling Regions
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2013-07-01,Tree Priors,63.15,Discriminative Transfer Learning with Tree-based Priors
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2014-04-14,DNN+Probabilistic Maxout,61.86,Improving Deep Neural Networks with Probabilistic Maxout Units
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2014-04-14,NiN,64.32,Network in Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2014-06-21,Stable and Efficient Representation Learning with Nonnegativity Constraints,60.8,Stable and Efficient Representation Learning with Nonnegativity Constraints
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2014-07-01,DSN,65.43,Deeply-Supervised Nets
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2014-09-22,SSCNN,75.7,Spatially-sparse convolutional neural networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2014-12-08,Deep Networks with Internal Selective Attention through Feedback Connections,66.22,Deep Networks with Internal Selective Attention through Feedback Connections
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-02-15,ACN,66.29,Striving for Simplicity: The All Convolutional Net
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-02-19,NiN+APL,69.17,Learning Activation Functions to Improve Deep Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-02-28,Fractional MP,73.61,Fractional Max-Pooling
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-05-02,Tuned CNN,72.6,Scalable Bayesian Optimization Using Deep Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-06-08,RCNN-96,68.25,Recurrent Convolutional Neural Network for Object Recognition
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-07-01,Deep Representation Learning with Target Coding,64.77,Deep Representation Learning with Target Coding
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-07-01,HD-CNN,67.38,HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-07-01,MLR DNN,68.53,Multi-Loss Regularized Deep Neural Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-07-12,DCNN+GFE,67.68,Deep Convolutional Neural Networks as Generic Feature Extractors
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-08-16,RReLU,59.75,Empirical Evaluation of Rectified Activations in Convolution Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-09-17,MIM,70.8,On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-10-05,Tree+Max-Avg pooling,67.63,"Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree"
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-10-11,SWWAE,69.12,Stacked What-Where Auto-encoders
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-11-09,BNM NiN,71.14,Batch-normalized Maxout Network in Network
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-11-18,CMsC,72.44,Competitive Multi-scale Convolution
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-12-07,VDN,67.76,Training Very Deep Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2015-12-07,Spectral Representations for Convolutional Neural Networks,68.4,Spectral Representations for Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2016-01-04,Fitnet4-LSUV,72.34,All you need is a good init
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2016-01-07,Exponential Linear Units,75.72,Fast and Accurate Deep Network Learning by Exponential Linear Units
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2016-05-15,Universum Prescription,67.16,Universum Prescription: Regularization using Unlabeled Data
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2016-05-20,ResNet-1001,77.29,Identity Mappings in Deep Residual Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2016-07-10,ResNet+ELU,73.45,Deep Residual Networks with Exponential Linear Unit
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2017-04-22,Evolution,77,Large-Scale Evolution of Image Classifiers
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2017-05-30,Deep Complex,72.91,Deep Complex Networks
Image Recognition,Vision,Image Recognition,CIFAR-10,CIFAR-100 Image Recognition,Percentage Correct,2017-06-06,NiN+Superclass+CDJ,69,Deep Convolutional Decision Jungle for Image Classification
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2010-08-31,NEC UIUC,0.28191,ImageNet Large Scale Visual Recognition Competition 2010 (ILSVRC2010)
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2011-10-26,XRCE,0.2577,ImageNet Large Scale Visual Recognition Competition 2011 (ILSVRC2011)
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2012-10-13,AlexNet / SuperVision,0.16422,ImageNet Large Scale Visual Recognition Competition 2012 (ILSVRC2012) (algorithm from ImageNet Classification with Deep Convolutional Neural Networks)
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2013-11-14,Clarifai,0.11743,ImageNet Large Scale Visual Recognition Competition 2013 (ILSVRC2013)
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2014-08-18,VGG,0.07405,ImageNet Large Scale Visual Recognition Competition 2014 (ILSVRC2014)
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2015-04-10,withdrawn,0.0458,Deep Image: Scaling up Image Recognition
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2015-12-10,MSRA,0.03567,ILSVRC2015 Results
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2016-09-26,Trimps-Soushen,0.02991,ILSVRC2016 Results
Image Recognition,Vision,Image Recognition,Imagenet,Imagenet Image Recognition,Error,2017-07-21,SE-ResNet152 / WMW,0.02251,ILSVRC2017 Results
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2002-07-01,ISVM,0.56,Training Invariant Support Vector Machines
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2002-07-01,Shape contexts,0.63,Shape matching and object recognition using shape contexts
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2003-07-01,Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis,0.4,Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2003-07-01,CNN+Gabor Filters,0.68,Handwritten Digit Recognition using Convolutional Neural Networks and Gabor Filters
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2003-07-01,CNN,1.19,Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2006-07-01,Energy-Based Sparse Represenation,0.39,Efficient Learning of Sparse Representations with an Energy-Based Model
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2006-07-01,Reducing the dimensionality of data with neural networks,1.2,Reducing the dimensionality of data with neural networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2007-07-01,Deformation Models,0.54,Deformation Models for Image Recognition
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2007-07-01,Trainable feature extractor,0.54,A trainable feature extractor for handwritten digit recognition
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2007-07-01,invariant feature hierarchies,0.62,Unsupervised learning of invariant feature hierarchies with applications to object recognition
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2008-07-01,Sparse Coding,0.59,Simple Methods for High-Performance Digit Recognition Based on Sparse Coding
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2008-07-01,DBN,1.12,CS81: Learning words with Deep Belief Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2008-07-01,Deep learning via semi-supervised embedding,1.5,Deep learning via semi-supervised embedding
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2009-07-01,The Best Multi-Stage Architecture,0.53,What is the Best Multi-Stage Architecture for Object Recognition?
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2009-07-01,CDBN,0.82,Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2009-07-01,Large-Margin kNN,0.94,Large-Margin kNN Classification using a Deep Encoder Network
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2009-07-01,Deep Boltzmann Machines,0.95,Deep Boltzmann Machines
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2010-03-01,DBSNN,0.35,Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2010-07-01,Supervised Translation-Invariant Sparse Coding,0.84,Supervised Translation-Invariant Sparse Coding
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2011-07-01,On Optimization Methods for Deep Learning,0.69,On Optimization Methods for Deep Learning
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2012-06-16,MCDNN,0.23,Multi-column Deep Neural Networks for Image Classification
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2012-06-16,Receptive Field Learning,0.64,Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2013-02-28,COSFIRE,0.52,Trainable COSFIRE Filters for Keypoint Detection and Pattern Recognition
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2013-06-16,DropConnect,0.21,Regularization of Neural Networks using DropConnect
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2013-06-16,Maxout Networks,0.45,Maxout Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2013-07-01,Sparse Activity and Sparse Connectivity in Supervised Learning,0.75,Sparse Activity and Sparse Connectivity in Supervised Learning
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2014-04-14,NiN,0.47,Network in Network
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2014-06-21,PCANet,0.62,PCANet: A Simple Deep Learning Baseline for Image Classification?
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2014-07-01,DSN,0.39,Deeply-Supervised Nets
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2014-07-01,StrongNet,1.1,StrongNet: mostly unsupervised image recognition with strong neurons
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2014-08-28,CKN,0.39,Convolutional Kernel Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-02-03,Explaining and Harnessing Adversarial Examples,0.78,Explaining and Harnessing Adversarial Examples
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-02-28,Fractional MP,0.32,Fractional Max-Pooling
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-03-11,C-SVDDNet,0.35,C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-04-05,HOPE,0.4,Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Probe and Learn Neural Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-05-13,APAC,0.23,APAC: Augmented PAttern Classification with Neural Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-05-31,FLSCNN,0.37,Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-06-08,RCNN-96,0.31,Recurrent Convolutional Neural Network for Object Recognition
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-06-12,ReNet,0.45,ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-07-01,MLR DNN,0.42,Multi-Loss Regularized Deep Neural Network
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-07-01,Deep Fried Convnets,0.71,Deep Fried Convnets
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-07-12,DCNN+GFE,0.46,Deep Convolutional Neural Networks as Generic Feature Extractors
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-09-17,MIM,0.35,On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-10-05,Tree+Max-Avg pooling,0.29,"Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree"
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-11-09,BNM NiN,0.24,Batch-normalized Maxout Network in Network
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-11-18,CMsC,0.33,Competitive Multi-scale Convolution
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-12-07,VDN,0.45,Training Very Deep Networks
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2015-12-07,BinaryConnect,1.01,BinaryConnect: Training Deep Neural Networks with binary weights during propagations
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2016-01-02,Convolutional Clustering,1.4,Convolutional Clustering for Unsupervised Learning
Image Recognition,Vision,Image Recognition,MNIST,MNIST handwritten digit recognition,Percentage Error,2016-01-04,Fitnet-LSUV-SVM,0.38,All you need is a good init
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2008-07-01,STF,67,Semantic Texton Forests for Image Categorization and Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2009-07-01,TextonBoost,57,TextonBoost for Image Understanding
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2010-07-01,Auto-Context,69,Auto-Context and Its Application to High-Level Vision Tasks and 3D Brain Image Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2010-07-01,HCRF+CO,77,Graph Cut based Inference with Co-occurrence Statistics
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2011-07-01,Are Spatial and Global Constraints Really Necessary for Segmentation?,77,Are Spatial and Global Constraints Really Necessary for Segmentation?
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2011-12-17,FC CRF,78,Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2012-06-16,"Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation",79,"Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation"
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2012-07-01,Harmony Potentials,80,Harmony Potentials - Fusing Local and Global Scale for Semantic Image Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2012-10-07,PMG,72.8,PatchMatchGraph: Building a Graph of Dense Patch Correspondences for Label Transfer
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2012-10-07,Kernelized SSVM/CRF,76,Structured Image Segmentation using Kernelized Features
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2013-10-29,MPP,78.2,Morphological Proximity Priors: Spatial Relationships for Semantic Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-class),Percentage Correct,2014-07-01,Large FC CRF,80.9,Large-Scale Semantic Co-Labeling of Image Sets
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2008-07-01,STF,72,Semantic Texton Forests for Image Categorization and Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2009-07-01,TextonBoost,72,TextonBoost for Image Understanding
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2010-07-01,Auto-Context,78,Auto-Context and Its Application to High-Level Vision Tasks and 3D Brain Image Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2010-07-01,HCRF+CO,87,Graph Cut based Inference with Co-occurrence Statistics
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2011-07-01,Are Spatial and Global Constraints Really Necessary for Segmentation?,85,Are Spatial and Global Constraints Really Necessary for Segmentation?
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2011-12-17,FC CRF,86,Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2012-06-16,"Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation",86,"Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation"
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2012-07-01,Harmony Potentials,83,Harmony Potentials - Fusing Local and Global Scale for Semantic Image Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2012-10-07,PatchMatchGraph,79,PatchMatchGraph: Building a Graph of Dense Patch Correspondences for Label Transfer
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2012-10-07,Kernelized SSVM/CRF,82,Structured Image Segmentation using Kernelized Features
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2013-10-29,MPP,85,Morphological Proximity Priors: Spatial Relationships for Semantic Segmentation
Image Recognition,Vision,Image Recognition,MSRC-21,MSRC-21 image semantic labelling (per-pixel),Percentage Correct,2014-07-01,Large FC CRF,86.8,Large-Scale Semantic Co-Labeling of Image Sets
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2011-12-17,Receptive Fields,60.1,Selecting Receptive Fields in Deep Networks
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2012-06-26,Invariant Representations with Local Transformations,58.7,Learning Invariant Representations with Local Transformations
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2012-07-01,Simulated Fixations,61,Deep Learning of Invariant Features via Simulated Fixations in Video
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2012-07-01,RGB-D Based Object Recognition,64.5,Unsupervised Feature Learning for RGB-D Based Object Recognition
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2012-12-03,Deep Learning of Invariant Features via Simulated Fixations in Video,56.5,Deep Learning of Invariant Features via Simulated Fixations in Video
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2012-12-03,Discriminative Learning of Sum-Product Networks,62.3,Discriminative Learning of Sum-Product Networks
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2013-01-15,Pooling-Invariant,58.28,Pooling-Invariant Image Feature Learning
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2013-07-01,Multi-Task Bayesian Optimization,70.1,Multi-Task Bayesian Optimization
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2014-02-24,No more meta-parameter tuning in unsupervised sparse feature learning,61,No more meta-parameter tuning in unsupervised sparse feature learning
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2014-06-21,Nonnegativity Constraints,67.9,Stable and Efficient Representation Learning with Nonnegativity Constraints
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2014-06-23,DFF Committees,68,Committees of deep feedforward networks trained with few data
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2014-08-28,CKN,62.32,Convolutional Kernel Networks
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2014-12-08,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks,72.8,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2015-02-13,An Analysis of Unsupervised Pre-training in Light of Recent Advances,70.2,An Analysis of Unsupervised Pre-training in Light of Recent Advances
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2015-03-11,C-SVDDNet,68.23,C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2015-07-01,Deep Representation Learning with Target Coding,73.15,Deep Representation Learning with Target Coding
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2015-10-11,SWWAE,74.33,Stacked What-Where Auto-encoders
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2016-01-02,Convolutional Clustering,74.1,Convolutional Clustering for Unsupervised Learning
Image Recognition,Vision,Image Recognition,STL-10,STL-10 Image Recognition,Percentage Correct,2016-11-19,CC-GAN²,77.79,Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2012-07-01,Convolutional neural networks applied to house numbers digit classification,4.9,Convolutional neural networks applied to house numbers digit classification
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2013-01-16,Stochastic Pooling,2.8,Stochastic Pooling for Regularization of Deep Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2013-06-16,Regularization of Neural Networks using DropConnect,1.94,Regularization of Neural Networks using DropConnect
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2013-06-16,Maxout,2.47,Maxout Networks
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2014-04-14,DCNN,2.16,Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2014-04-14,NiN,2.35,Network in Network
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2014-07-01,DSN,1.92,Deeply-Supervised Nets
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-05-31,FLSCNN,3.96,Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-06-08,RCNN-96,1.77,Recurrent Convolutional Neural Network for Object Recognition
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-06-12,ReNet,2.38,ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-07-01,MLR DNN,1.92,Multi-Loss Regularized Deep Neural Network
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-09-17,MIM,1.97,On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-10-05,Tree+Max-Avg pooling,1.69,"Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree"
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-11-09,BNM NiN,1.81,Batch-normalized Maxout Network in Network
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-11-18,CMsC,1.76,Competitive Multi-scale Convolution
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2015-12-07,BinaryConnect,2.15,BinaryConnect: Training Deep Neural Networks with binary weights during propagations
Image Recognition,Vision,Image Recognition,SVHN,Street House View Numbers (SVHN),Percentage Error,2017-05-30,Deep Complex,3.3,Deep Complex Networks
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract 1.0 multiple choice,Percentage Correct,2016-07-01,LSTM blind,61.41,VQA: Visual Question Answering (algorithm from Yin and Yang: Balancing and Answering Binary Visual Questions)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract 1.0 multiple choice,Percentage Correct,2016-07-01,LSTM + global features,69.21,VQA: Visual Question Answering (algorithm from Yin and Yang: Balancing and Answering Binary Visual Questions)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract 1.0 multiple choice,Percentage Correct,2016-07-01,Dualnet ensemble,71.18,VQA: Visual Question Answering (algorithm from DualNet: Domain-Invariant Network for Visual Question Answering)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract 1.0 multiple choice,Percentage Correct,2016-09-19,Graph VQA,74.37,Graph-Structured Representations for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract images 1.0 open ended,Percentage Correct,2016-07-01,LSTM blind,57.19,VQA: Visual Question Answering (algorithm from Yin and Yang: Balancing and Answering Binary Visual Questions)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract images 1.0 open ended,Percentage Correct,2016-07-01,LSTM + global features,65.02,VQA: Visual Question Answering (algorithm from Yin and Yang: Balancing and Answering Binary Visual Questions)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract images 1.0 open ended,Percentage Correct,2016-07-01,Dualnet ensemble,69.73,VQA: Visual Question Answering (algorithm from DualNet: Domain-Invariant Network for Visual Question Answering)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) abstract images 1.0 open ended,Percentage Correct,2016-09-19,Graph VQA,70.42,Graph-Structured Representations for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,Percentage Correct,2015-05-03,LSTM Q+I,63.1,VQA: Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,Percentage Correct,2015-12-15,iBOWIMG baseline,61.97,Simple Baseline for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,Percentage Correct,2016-04-06,FDA,64.2,A Focused Dynamic Attention Model for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,Percentage Correct,2016-05-31,HQI+ResNet,66.1,Hierarchical Co-Attention for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,Percentage Correct,2016-06-05,MRN,66.33,Multimodal Residual Learning for Visual QA
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,Percentage Correct,2016-06-06,MCB 7 att.,70.1,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding (source code)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,Percentage Correct,2016-08-06,joint-loss,67.3,Training Recurrent Answering Units with Joint Loss Minimization for VQA
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2015-05-03,LSTM Q+I,58.2,VQA: Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2015-12-15,iBOWIMG baseline,55.89,Simple Baseline for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-01-26,SAN,58.9,Stacked Attention Networks for Image Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-03-09,CNN-RNN,59.5,Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-03-19,SMem-VQA,58.24,"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering"
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-04-06,FDA,59.5,A Focused Dynamic Attention Model for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-05-31,HQI+ResNet,62.1,Hierarchical Co-Attention for Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-06-05,MRN + global features,61.84,Multimodal Residual Learning for Visual QA
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-06-06,MCB 7 att.,66.5,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding (source code)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2016-08-06,joint-loss,63.2,Training Recurrent Answering Units with Joint Loss Minimization for VQA
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 1.0 open ended,Percentage Correct,2017-08-06,N2NMN,64.2,Learning to Reason: End-to-End Module Networks for Visual Question Answering (source code)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 2.0 open ended,Percentage Correct,2016-12-02,d-LSTM+nI,54.22,Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering (algorithm from GitHub - VT-vision-lab/VQA_LSTM_CNN: Train a deeper LSTM and normalized CNN Visual Question Answering model. This current code can get 58.16 on OpenEnded and 63.09 on Multiple-Choice on test-standard.)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 2.0 open ended,Percentage Correct,2016-12-02,MCB,62.27,Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering (algorithm from Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding)
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 2.0 open ended,Percentage Correct,2017-07-25,Up-Down,70.34,Bottom-Up and Top-Down Attention for Image Captioning and VQA
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 2.0 open ended,Percentage Correct,2017-07-26,DLAIT,68.07,VQA: Visual Question Answering
Visual QA,Vision,Visual Question Answering,COCO,COCO Visual Question Answering (VQA) real images 2.0 open ended,Percentage Correct,2017-07-26,HDU-USYD-UNCC,68.16,VQA: Visual Question Answering
Visual QA,Vision,Visual Question Answering,Visual7W,Visual7W,Percentage Correct,2016-06-06,MCB+Att.,62.2,Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
Visual QA,Vision,Visual Question Answering,Visual7W,Visual7W,Percentage Correct,2016-11-30,CMN,72.53,Modeling Relationships in Referential Expressions with Compositional Modular Networks
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1984-12-31,Novag Super Constellation 6502 4 MHz,1631,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1985-12-31,Mephisto Amsterdam 68000 12 MHz,1827,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1986-12-31,Mephisto Amsterdam 68000 12 MHz,1827,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1987-12-31,Mephisto Dallas 68020 14 MHz,1923,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1988-12-31,Mephisto MM 4 Turbo Kit 6502 16 MHz,1993,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1989-12-31,Mephisto Portorose 68020 12 MHz,2027,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1990-12-31,Mephisto Portorose 68030 36 MHz,2138,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1991-12-31,Mephisto Vancouver 68030 36 MHz,2127,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1992-12-31,Chess Machine Schroder 3.0 ARM2 30 MHz,2174,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1993-12-31,Mephisto Genius 2.0 486/50-66 MHz,2235,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1995-12-31,MChess Pro 5.0 Pentium 90 MHz,2306,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1996-12-31,Rebel 8.0 Pentium 90 MHz,2337,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1997-05-11,Deep Blue,2725,What was Deep Blue's Elo rating? - Quora
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1997-12-31,HIARCS 6.0 49MB P200 MMX,2418,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1998-12-31,Fritz 5.0 PB29% 67MB P200 MMX,2460,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,1999-12-31,Chess Tiger 12.0 DOS 128MB K6-2 450 MHz,2594,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2000-12-31,Fritz 6.0 128MB K6-2 450 MHz,2607,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2001-12-31,Chess Tiger 14.0 CB 256MB Athlon 1200,2709,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2002-12-31,Deep Fritz 7.0 256MB Athlon 1200 MHz,2759,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2003-12-31,Shredder 7.04 UCI 256MB Athlon 1200 MHz,2791,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2004-12-31,Shredder 8.0 CB 256MB Athlon 1200 MHz,2800,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2005-12-31,Shredder 9.0 UCI 256MB Athlon 1200 MHz,2808,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2006-05-27,Rybka 1.1 64bit,2995,CCRL 40/40 - Complete list
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2006-12-31,Rybka 1.2 256MB Athlon 1200 MHz,2902,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2007-12-31,Rybka 2.3.1 Arena 256MB Athlon 1200 MHz,2935,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2008-12-31,Deep Rybka 3 2GB Q6600 2.4 GHz,3238,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2009-12-31,Deep Rybka 3 2GB Q6600 2.4 GHz,3232,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2010-08-07,Rybka 4 64bit,3269,CCRL 40/40 - Complete list
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2010-12-31,Deep Rybka 3 2GB Q6600 2.4 GHz,3227,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2011-12-31,Deep Rybka 4 2GB Q6600 2.4 GHz,3216,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2012-12-31,Deep Rybka 4 x64 2GB Q6600 2.4 GHz,3221,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2013-07-20,Houdini 3 64bit,3248,Wayback Machine
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2013-12-31,Komodo 5.1 MP x64 2GB Q6600 2.4 GHz,3241,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2014-12-31,Komodo 7.0 MP x64 2GB Q6600 2.4 GHz,3295,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2015-07-04,Komodo 9,3332,CCRL 40/40 - Complete list
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2015-12-31,Stockfish 6 MP x64 2GB Q6600 2.4 GHz,3334,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2016-12-31,Komodo 9.1 MP x64 2GB Q6600 2.4 GHz,3366,Swedish Chess Computer Association - Wikipedia
Abstract Strategy Games,Game Playing,Abstract Strategy Games,Chess,Chess,ELO,2017-02-27,Stockfish,3393,CCRL 40/40 - Index
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2012-07-14,SARSA,103.2,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2012-07-19,Best linear,939.2,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-02-26,Nature DQN,3069,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-07-15,Gorila,813.5,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-09-22,DQN hs,634,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-09-22,DQN noop,1620,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-11-20,Duel hs,1486.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-11-20,DDQN (tuned) noop,3747.7,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-11-20,Duel noop,4461.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-12-08,Prior+Duel hs,823.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2015-12-08,DDQN (tuned) hs,1033.4,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2016-01-06,Prior hs,1334.7,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2016-01-06,Prior noop,4203.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2016-02-24,DDQN+Pop-Art noop,3213.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2016-04-05,Prior+Duel noop,3941,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2016-04-10,A3C FF (1 day) hs,182.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2016-04-10,A3C FF hs,518.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2016-04-10,A3C LSTM hs,945.3,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2017-03-10,ES FF (1 hour) noop,994,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Alien,Raw Score,2017-07-21,C51 noop,3166,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2012-07-14,SARSA,183.6,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2012-07-19,Best linear,103.4,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-02-26,Nature DQN,739.5,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-07-15,Gorila,189.2,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-09-22,DQN hs,178.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-09-22,DQN noop,978,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-11-20,Duel hs,172.7,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-11-20,DDQN (tuned) noop,1793.3,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-11-20,Duel noop,2354.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-12-08,DDQN (tuned) hs,169.1,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2015-12-08,Prior+Duel hs,238.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2016-01-06,Prior hs,129.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2016-01-06,Prior noop,1838.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2016-02-24,DDQN+Pop-Art noop,782.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2016-04-05,Prior+Duel noop,2296.8,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2016-04-10,A3C LSTM hs,173,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2016-04-10,A3C FF hs,263.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2016-04-10,A3C FF (1 day) hs,283.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2017-03-10,ES FF (1 hour) noop,112,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Amidar,Raw Score,2017-07-21,C51 noop,1735,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2012-07-14,SARSA,537,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2012-07-19,Best linear,628,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-02-26,Nature DQN,3359,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-07-15,Gorila,1195.8,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-09-22,DQN hs,3489.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-09-22,DQN noop,4280.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-11-20,Duel hs,3994.8,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-11-20,Duel noop,4621,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-11-20,DDQN (tuned) noop,5393.2,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-12-08,DDQN (tuned) hs,6060.8,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2015-12-08,Prior+Duel hs,10950.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2016-01-06,Prior hs,6548.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2016-01-06,Prior noop,7672.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2016-02-24,DDQN+Pop-Art noop,9011.6,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2016-04-05,Prior+Duel noop,11477,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2016-04-10,A3C FF (1 day) hs,3746.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2016-04-10,A3C FF hs,5474.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2016-04-10,A3C LSTM hs,14497.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2017-03-10,ES FF (1 hour) noop,1673.9,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Assault,Raw Score,2017-07-21,C51 noop,7203,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2012-07-14,SARSA,1332,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2012-07-19,Best linear,987.3,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-02-26,Nature DQN,6012,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-07-15,Gorila,3324.7,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-09-22,DQN hs,3170.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-09-22,DQN noop,4359,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-11-20,Duel hs,15840,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-11-20,DDQN (tuned) noop,17356.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-11-20,Duel noop,28188,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-12-08,DDQN (tuned) hs,16837,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2015-12-08,Prior+Duel hs,364200,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2016-01-06,Prior hs,22484.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2016-01-06,Prior noop,31527,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2016-02-24,DDQN+Pop-Art noop,18919.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2016-04-05,Prior+Duel noop,375080,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2016-04-10,A3C FF (1 day) hs,6723,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2016-04-10,A3C LSTM hs,17244.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2016-04-10,A3C FF hs,22140.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2017-03-10,ES FF (1 hour) noop,1440,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asterix,Raw Score,2017-07-21,C51 noop,406211,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2012-07-14,SARSA,89,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2012-07-19,Best linear,907.3,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-02-26,Nature DQN,1629,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-07-15,Gorila,933.6,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-09-22,DQN noop,1364.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-09-22,DQN hs,1458.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-11-20,DDQN (tuned) noop,734.7,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-11-20,Duel hs,2035.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-11-20,Duel noop,2837.7,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-12-08,Prior+Duel hs,1021.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2015-12-08,DDQN (tuned) hs,1193.2,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2016-01-06,Prior hs,1745.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2016-01-06,Prior noop,2654.3,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2016-02-24,DDQN+Pop-Art noop,2869.3,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2016-04-05,Prior+Duel noop,1192.7,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2016-04-10,A3C FF (1 day) hs,3009.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2016-04-10,A3C FF hs,4474.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2016-04-10,A3C LSTM hs,5093.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2017-03-10,ES FF (1 hour) noop,1562,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Asteroids,Raw Score,2017-07-21,C51 noop,1516,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2012-07-14,SARSA,852.9,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2012-07-19,Best linear,62687,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-02-26,Nature DQN,85641,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-07-15,Gorila,629166.5,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-09-22,DQN noop,279987,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-09-22,DQN hs,292491,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-11-20,DDQN (tuned) noop,106056,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-11-20,Duel noop,382572,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-11-20,Duel hs,445360,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-12-08,DDQN (tuned) hs,319688,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2015-12-08,Prior+Duel hs,423252,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2016-01-06,Prior hs,330647,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2016-01-06,Prior noop,357324,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2016-02-24,DDQN+Pop-Art noop,340076,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2016-04-05,Prior+Duel noop,395762,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2016-04-10,A3C FF (1 day) hs,772392,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2016-04-10,A3C LSTM hs,875822,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2016-04-10,A3C FF hs,911091,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2017-03-10,ES FF (1 hour) noop,1267410,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Atlantis,Raw Score,2017-07-21,C51 noop,841075,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2012-07-14,SARSA,67.4,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2012-07-19,Best linear,190.8,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-02-26,Nature DQN,429.7,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-07-15,Gorila,399.4,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-09-22,DQN hs,312.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-09-22,DQN noop,455,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-11-20,DDQN (tuned) noop,1030.6,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-11-20,Duel hs,1129.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-11-20,Duel noop,1611.9,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-12-08,DDQN (tuned) hs,886,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2015-12-08,Prior+Duel hs,1004.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2016-01-06,Prior hs,876.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2016-01-06,Prior noop,1054.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2016-02-24,DDQN+Pop-Art noop,1103.3,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2016-04-05,Prior+Duel noop,1503.1,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2016-04-10,A3C LSTM hs,932.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2016-04-10,A3C FF (1 day) hs,946,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2016-04-10,A3C FF hs,970.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2017-03-10,ES FF (1 hour) noop,225,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bank Heist,Raw Score,2017-07-21,C51 noop,976,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2012-07-14,SARSA,16.2,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2012-07-19,Best linear,15820,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-02-26,Nature DQN,26300,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-07-15,Gorila,19938,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-09-22,DQN hs,23750,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-09-22,DQN noop,29900,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-11-20,Duel hs,31320,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-11-20,DDQN (tuned) noop,31700,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-11-20,Duel noop,37150,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-12-08,DDQN (tuned) hs,24740,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2015-12-08,Prior+Duel hs,30650,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2016-01-06,Prior hs,25520,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2016-01-06,Prior noop,31530,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2016-02-24,DDQN+Pop-Art noop,8220,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2016-04-05,Prior+Duel noop,35520,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2016-04-10,A3C FF (1 day) hs,11340,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2016-04-10,A3C FF hs,12950,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2016-04-10,A3C LSTM hs,20760,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2017-03-10,ES FF (1 hour) noop,16600,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Battle Zone,Raw Score,2017-07-21,C51 noop,28742,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2012-07-14,SARSA,1743,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2012-07-19,Best linear,929.4,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2013-12-19,DQN best,5184,Playing Atari with Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-02-26,Nature DQN,6846,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-07-15,Gorila,3822.1,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-09-22,DQN noop,8627.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-09-22,DQN hs,9743.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-11-20,Duel noop,12164,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-11-20,DDQN (tuned) noop,13772.8,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-11-20,Duel hs,14591.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-12-08,DDQN (tuned) hs,17417.2,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2015-12-08,Prior+Duel hs,37412.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2016-01-06,Prior noop,23384.2,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2016-01-06,Prior hs,31181.3,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2016-02-24,DDQN+Pop-Art noop,8299.4,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2016-04-05,Prior+Duel noop,30276.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2016-04-10,A3C FF (1 day) hs,13235.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2016-04-10,A3C FF hs,22707.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2016-04-10,A3C LSTM hs,24622.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2017-03-10,ES FF (1 hour) noop,744,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Beam Rider,Raw Score,2017-07-21,C51 noop,14074,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2015-09-22,DQN hs,493.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2015-09-22,DQN noop,585.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2015-11-20,Duel hs,910.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2015-11-20,DDQN (tuned) noop,1225.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2015-11-20,Duel noop,1472.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2015-12-08,DDQN (tuned) hs,1011.1,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2015-12-08,Prior+Duel hs,2178.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2016-01-06,Prior hs,865.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2016-01-06,Prior noop,1305.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2016-02-24,DDQN+Pop-Art noop,1199.6,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2016-04-05,Prior+Duel noop,3409,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2016-04-10,A3C FF hs,817.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2016-04-10,A3C LSTM hs,862.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2016-04-10,A3C FF (1 day) hs,1433.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2017-03-10,ES FF (1 hour) noop,686,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Berzerk,Raw Score,2017-07-21,C51 noop,1645,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2012-07-14,SARSA,36.4,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2012-07-19,Best linear,43.9,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-02-26,Nature DQN,42.4,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-07-15,Gorila,54,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-09-22,DQN noop,50.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-09-22,DQN hs,56.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-11-20,Duel noop,65.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-11-20,Duel hs,65.7,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-11-20,DDQN (tuned) noop,68.1,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-12-08,Prior+Duel hs,50.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2015-12-08,DDQN (tuned) hs,69.6,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2016-01-06,Prior noop,47.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2016-01-06,Prior hs,52,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2016-02-24,DDQN+Pop-Art noop,102.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2016-04-05,Prior+Duel noop,46.7,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2016-04-10,A3C FF hs,35.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2016-04-10,A3C FF (1 day) hs,36.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2016-04-10,A3C LSTM hs,41.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2017-03-10,ES FF (1 hour) noop,30,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Bowling,Raw Score,2017-07-21,C51 noop,81.8,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2012-07-14,SARSA,9.8,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2012-07-19,Best linear,44,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-02-26,Nature DQN,71.8,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-07-15,Gorila,74.2,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-09-22,DQN hs,70.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-09-22,DQN noop,88,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-11-20,Duel hs,77.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-11-20,DDQN (tuned) noop,91.6,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-11-20,Duel noop,99.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-12-08,DDQN (tuned) hs,73.5,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2015-12-08,Prior+Duel hs,79.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2016-01-06,Prior hs,72.3,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2016-01-06,Prior noop,95.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2016-02-24,DDQN+Pop-Art noop,99.3,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2016-04-05,Prior+Duel noop,98.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2016-04-10,A3C FF (1 day) hs,33.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2016-04-10,A3C LSTM hs,37.3,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2016-04-10,A3C FF hs,59.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2017-03-10,ES FF (1 hour) noop,49.8,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Boxing,Raw Score,2017-07-21,C51 noop,97.8,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2012-07-14,SARSA,6.1,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2012-07-19,Best linear,5.2,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2013-12-19,DQN best,225,Playing Atari with Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-02-26,Nature DQN,401.2,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-07-15,Gorila,313,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-09-22,DQN hs,354.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-09-22,DQN noop,385.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-11-20,Duel noop,345.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-11-20,Duel hs,411.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-11-20,DDQN (tuned) noop,418.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-12-08,Prior+Duel hs,354.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2015-12-08,DDQN (tuned) hs,368.9,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2016-01-06,Prior hs,343,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2016-01-06,Prior noop,373.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2016-02-24,DDQN+Pop-Art noop,344.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2016-04-05,Prior+Duel noop,366,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2016-04-10,A3C FF (1 day) hs,551.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2016-04-10,A3C FF hs,681.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2016-04-10,A3C LSTM hs,766.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2017-03-10,ES FF (1 hour) noop,9.5,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Breakout,Raw Score,2017-07-21,C51 noop,748,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2012-07-14,SARSA,4647,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2012-07-19,Best linear,8803,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-02-26,Nature DQN,8309,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-07-15,Gorila,6296.9,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-09-22,DQN hs,3973.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-09-22,DQN noop,4657.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-11-20,Duel hs,4881,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-11-20,DDQN (tuned) noop,5409.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-11-20,Duel noop,7561.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-12-08,DDQN (tuned) hs,3853.5,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2015-12-08,Prior+Duel hs,5570.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2016-01-06,Prior hs,3489.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2016-01-06,Prior noop,4463.2,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2016-02-24,DDQN+Pop-Art noop,49065.8,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2016-04-05,Prior+Duel noop,7687.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2016-04-10,A3C LSTM hs,1997,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2016-04-10,A3C FF (1 day) hs,3306.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2016-04-10,A3C FF hs,3755.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2017-03-10,ES FF (1 hour) noop,7783.9,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Centipede,Raw Score,2017-07-21,C51 noop,9646,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2012-07-14,SARSA,16.9,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2012-07-19,Best linear,1582,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-02-26,Nature DQN,6687,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-07-15,Gorila,3191.8,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-09-22,DQN hs,5017,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-09-22,DQN noop,6126,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-11-20,Duel hs,3784,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-11-20,DDQN (tuned) noop,5809,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-11-20,Duel noop,11215,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-12-08,DDQN (tuned) hs,3495,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2015-12-08,Prior+Duel hs,8058,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2016-01-06,Prior hs,4635,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2016-01-06,Prior noop,8600,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2016-02-24,DDQN+Pop-Art noop,775,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2016-04-05,Prior+Duel noop,13185,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2016-04-10,A3C FF (1 day) hs,4669,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2016-04-10,A3C FF hs,7021,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2016-04-10,A3C LSTM hs,10150,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2017-03-10,ES FF (1 hour) noop,3710,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Chopper Command,Raw Score,2017-07-21,C51 noop,15600,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2012-07-14,SARSA,149.8,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2012-07-19,Best linear,23411,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-02-26,Nature DQN,114103,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-07-15,Gorila,65451,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-09-22,DQN hs,98128,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-09-22,DQN noop,110763,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-11-20,DDQN (tuned) noop,117282,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-11-20,Duel hs,124566,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-11-20,Duel noop,143570,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-12-08,DDQN (tuned) hs,113782,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2015-12-08,Prior+Duel hs,127853,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2016-01-06,Prior hs,127512,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2016-01-06,Prior noop,141161,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2016-02-24,DDQN+Pop-Art noop,119679,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2016-04-05,Prior+Duel noop,162224,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2016-04-10,A3C FF (1 day) hs,101624,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2016-04-10,A3C FF hs,112646,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2016-04-10,A3C LSTM hs,138518,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2017-03-10,ES FF (1 hour) noop,26430,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Crazy Climber,Raw Score,2017-07-21,C51 noop,179877,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2015-09-22,DQN hs,15917.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2015-09-22,DQN noop,23633,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2015-11-20,Duel hs,33996,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2015-11-20,DDQN (tuned) noop,35338.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2015-11-20,Duel noop,42214,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2015-12-08,DDQN (tuned) hs,27510,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2015-12-08,Prior+Duel hs,34415,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2016-01-06,Prior hs,23666.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2016-01-06,Prior noop,31286.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2016-02-24,DDQN+Pop-Art noop,11099,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2016-04-05,Prior+Duel noop,41324.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2016-04-10,A3C FF (1 day) hs,36242.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2016-04-10,A3C FF hs,56533,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2016-04-10,A3C LSTM hs,233021.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Defender,Raw Score,2017-07-21,C51 noop,47092,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2012-07-14,SARSA,0,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2012-07-19,Best linear,520.5,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-02-26,Nature DQN,9711,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-07-15,Gorila,14880.1,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-09-22,DQN noop,12149.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-09-22,DQN hs,12550.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-11-20,Duel hs,56322.8,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-11-20,DDQN (tuned) noop,58044.2,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-11-20,Duel noop,60813.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-12-08,DDQN (tuned) hs,69803.4,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2015-12-08,Prior+Duel hs,73371.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2016-01-06,Prior hs,61277.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2016-01-06,Prior noop,71846.4,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2016-02-24,DDQN+Pop-Art noop,63644.9,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2016-04-05,Prior+Duel noop,72878.6,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2016-04-10,A3C FF (1 day) hs,84997.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2016-04-10,A3C FF hs,113308.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2016-04-10,A3C LSTM hs,115201.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2017-03-10,ES FF (1 hour) noop,1166.5,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Demon Attack,Raw Score,2017-07-21,C51 noop,130955,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2012-07-14,SARSA,-16,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2012-07-19,Best linear,-13.1,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-02-26,Nature DQN,-18.1,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-07-15,Gorila,-11.3,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-09-22,DQN noop,-6.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-09-22,DQN hs,-6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-11-20,DDQN (tuned) noop,-5.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-11-20,Duel hs,-0.8,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-11-20,Duel noop,0.1,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-12-08,Prior+Duel hs,-10.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2015-12-08,DDQN (tuned) hs,-0.3,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2016-01-06,Prior hs,16,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2016-01-06,Prior noop,18.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2016-02-24,DDQN+Pop-Art noop,-11.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2016-04-05,Prior+Duel noop,-12.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2016-04-10,A3C FF hs,-0.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2016-04-10,A3C FF (1 day) hs,0.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2016-04-10,A3C LSTM hs,0.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2017-03-10,ES FF (1 hour) noop,0.2,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Double Dunk,Raw Score,2017-07-21,C51 noop,2.5,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2012-07-14,SARSA,159.4,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2012-07-19,Best linear,129.1,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2013-12-19,DQN best,661,Playing Atari with Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-02-26,Nature DQN,301.8,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-07-15,Gorila,71,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-09-22,DQN hs,626.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-09-22,DQN noop,729,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-11-20,DDQN (tuned) noop,1211.8,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-11-20,Duel hs,2077.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-11-20,Duel noop,2258.2,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-12-08,DDQN (tuned) hs,1216.6,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2015-12-08,Prior+Duel hs,2223.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2016-01-06,Prior hs,1831,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2016-01-06,Prior noop,2093,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2016-02-24,DDQN+Pop-Art noop,2002.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2016-04-05,Prior+Duel noop,2306.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2016-04-10,A3C FF hs,-82.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2016-04-10,A3C LSTM hs,-82.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2016-04-10,A3C FF (1 day) hs,-82.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2017-03-10,ES FF (1 hour) noop,95,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Enduro,Raw Score,2017-07-21,C51 noop,3454,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2012-07-14,SARSA,-85.1,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2012-07-19,Best linear,-89.5,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-02-26,Nature DQN,-0.8,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-07-15,Gorila,4.6,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-09-22,DQN noop,-4.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-09-22,DQN hs,-1.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-11-20,Duel hs,-4.1,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-11-20,DDQN (tuned) noop,15.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-11-20,Duel noop,46.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-12-08,DDQN (tuned) hs,3.2,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2015-12-08,Prior+Duel hs,17,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2016-01-06,Prior hs,9.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2016-01-06,Prior noop,39.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2016-02-24,DDQN+Pop-Art noop,45.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2016-04-05,Prior+Duel noop,41.3,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2016-04-10,A3C FF (1 day) hs,13.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2016-04-10,A3C FF hs,18.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2016-04-10,A3C LSTM hs,22.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2017-03-10,ES FF (1 hour) noop,-49,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Fishing Derby,Raw Score,2017-07-21,C51 noop,8.9,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2012-07-14,SARSA,19.7,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2012-07-19,Best linear,19.1,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-02-26,Nature DQN,30.3,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-07-15,Gorila,10.2,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-09-10,MP-EB,27,Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-09-22,DQN hs,26.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-09-22,DQN noop,30.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-11-20,Duel noop,0,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-11-20,Duel hs,0.2,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-11-20,DDQN (tuned) noop,33.3,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-12-08,Prior+Duel hs,28.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2015-12-08,DDQN (tuned) hs,28.8,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-01-06,Prior hs,28.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-01-06,Prior noop,33.7,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-02-24,DDQN+Pop-Art noop,33.4,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-04-05,Prior+Duel noop,33,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-04-10,A3C FF (1 day) hs,0.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-04-10,A3C FF hs,0.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-04-10,A3C LSTM hs,0.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-08-22,A3C-CTS,30.48,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2016-12-13,TRPO-hash,34,Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2017-03-03,DQN-PixelCNN,31.7,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2017-03-03,DQN-CTS,33,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2017-03-10,ES FF (1 hour) noop,31,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2017-06-25,Sarsa-φ-EB,0,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2017-06-25,Sarsa-ε,29.9,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Freeway,Raw Score,2017-07-21,C51 noop,33.9,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2012-07-14,SARSA,180.9,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2012-07-19,Best linear,216.9,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-02-26,Nature DQN,328.3,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-07-15,Gorila,426.6,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-09-10,MP-EB,507,Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-09-22,DQN hs,496.1,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-09-22,DQN noop,797.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-11-20,DDQN (tuned) noop,1683.3,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-11-20,Duel hs,2332.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-11-20,Duel noop,4672.8,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-12-08,DDQN (tuned) hs,1448.1,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2015-12-08,Prior+Duel hs,4038.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-01-06,Prior hs,3510,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-01-06,Prior noop,4380.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-02-24,DDQN+Pop-Art noop,3469.6,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-04-05,Prior+Duel noop,7413,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-04-10,A3C FF (1 day) hs,180.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-04-10,A3C FF hs,190.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-04-10,A3C LSTM hs,197.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2016-12-13,TRPO-hash,5214,Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2017-03-10,ES FF (1 hour) noop,370,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2017-06-25,Sarsa-ε,1394.3,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2017-06-25,Sarsa-φ-EB,2770.1,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Frostbite,Raw Score,2017-07-21,C51 noop,3965,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2012-07-14,SARSA,2368,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2012-07-19,Best linear,1288,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-02-26,Nature DQN,8520,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-07-15,Gorila,4373,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-09-22,DQN hs,8190.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-09-22,DQN noop,8777.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-11-20,DDQN (tuned) noop,14840.8,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-11-20,Duel noop,15718.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-11-20,Duel hs,20051.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-12-08,DDQN (tuned) hs,15253,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2015-12-08,Prior+Duel hs,105148.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2016-01-06,Prior noop,32487.2,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2016-01-06,Prior hs,34858.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2016-02-24,DDQN+Pop-Art noop,56218.2,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2016-04-05,Prior+Duel noop,104368.2,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2016-04-10,A3C FF (1 day) hs,8442.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2016-04-10,A3C FF hs,10022.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2016-04-10,A3C LSTM hs,17106.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2017-03-10,ES FF (1 hour) noop,582,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gopher,Raw Score,2017-07-21,C51 noop,33641,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2012-07-14,SARSA,429,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2012-07-19,Best linear,387.7,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-02-26,Nature DQN,306.7,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-07-15,Gorila,538.4,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-09-22,DQN hs,298,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-09-22,DQN noop,473,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-11-20,Duel hs,297,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-11-20,DDQN (tuned) noop,412,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-11-20,Duel noop,588,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-12-08,Prior+Duel hs,167,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2015-12-08,DDQN (tuned) hs,200.5,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-01-06,Prior hs,269.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-01-06,Prior noop,548.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-02-24,DDQN+Pop-Art noop,483.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-04-05,Prior+Duel noop,238,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-04-10,A3C FF (1 day) hs,269.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-04-10,A3C FF hs,303.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-04-10,A3C LSTM hs,320,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2016-08-22,A3C-CTS,238.68,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2017-03-03,DQN-CTS,238,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2017-03-03,DQN-PixelCNN,498.3,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2017-03-10,ES FF (1 hour) noop,805,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Gravitar,Raw Score,2017-07-21,C51 noop,440,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2012-07-14,SARSA,7295,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2012-07-19,Best linear,6459,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-02-26,Nature DQN,19950,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-07-15,Gorila,8963.4,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-09-22,DQN hs,14992.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-09-22,DQN noop,20437.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-11-20,Duel hs,15207.9,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-11-20,DDQN (tuned) noop,20130.2,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-11-20,Duel noop,20818.2,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-12-08,DDQN (tuned) hs,14892.5,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2015-12-08,Prior+Duel hs,15459.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2016-01-06,Prior hs,20889.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2016-01-06,Prior noop,23037.7,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2016-02-24,DDQN+Pop-Art noop,14225.2,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2016-04-05,Prior+Duel noop,21036.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2016-04-10,A3C FF (1 day) hs,28765.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2016-04-10,A3C LSTM hs,28889.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2016-04-10,A3C FF hs,32464.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 HERO,Raw Score,2017-07-21,C51 noop,38874,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2012-07-14,SARSA,-3.2,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2012-07-19,Best linear,-9.5,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-02-26,Nature DQN,-1.6,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-07-15,Gorila,-1.7,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-09-22,DQN noop,-1.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-09-22,DQN hs,-1.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-11-20,DDQN (tuned) noop,-2.7,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-11-20,Duel hs,-1.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-11-20,Duel noop,0.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-12-08,DDQN (tuned) hs,-2.5,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2015-12-08,Prior+Duel hs,0.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2016-01-06,Prior hs,-0.2,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2016-01-06,Prior noop,1.3,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2016-02-24,DDQN+Pop-Art noop,-4.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2016-04-05,Prior+Duel noop,-0.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2016-04-10,A3C FF (1 day) hs,-4.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2016-04-10,A3C FF hs,-2.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2016-04-10,A3C LSTM hs,-1.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2017-03-10,ES FF (1 hour) noop,-4.1,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ice Hockey,Raw Score,2017-07-21,C51 noop,-3.5,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2012-07-14,SARSA,354.1,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2012-07-19,Best linear,202.8,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-02-26,Nature DQN,576.7,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-07-15,Gorila,444,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-09-22,DQN hs,697.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-09-22,DQN noop,768.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-11-20,Duel hs,835.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-11-20,Duel noop,1312.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-11-20,DDQN (tuned) noop,1358,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-12-08,DDQN (tuned) hs,573,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2015-12-08,Prior+Duel hs,585,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2016-01-06,Prior hs,3961,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2016-01-06,Prior noop,5148,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2016-02-24,DDQN+Pop-Art noop,507.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2016-04-05,Prior+Duel noop,812,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2016-04-10,A3C FF (1 day) hs,351.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2016-04-10,A3C FF hs,541,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2016-04-10,A3C LSTM hs,613,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 James Bond,Raw Score,2017-07-21,C51 noop,1909,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2012-07-14,SARSA,8.8,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2012-07-19,Best linear,1622,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-02-26,Nature DQN,6740,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-07-15,Gorila,1431,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-09-22,DQN hs,4496,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-09-22,DQN noop,7259,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-11-20,Duel hs,10334,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-11-20,DDQN (tuned) noop,12992,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-11-20,Duel noop,14854,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-12-08,Prior+Duel hs,861,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2015-12-08,DDQN (tuned) hs,11204,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2016-01-06,Prior hs,12185,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2016-01-06,Prior noop,16200,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2016-02-24,DDQN+Pop-Art noop,13150,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2016-04-05,Prior+Duel noop,1792,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2016-04-10,A3C FF hs,94,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2016-04-10,A3C FF (1 day) hs,106,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2016-04-10,A3C LSTM hs,125,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2017-03-10,ES FF (1 hour) noop,11200,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kangaroo,Raw Score,2017-07-21,C51 noop,12853,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2012-07-14,SARSA,3341,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2012-07-19,Best linear,3372,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-02-26,Nature DQN,3805,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-07-15,Gorila,6363.1,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-09-22,DQN hs,6206,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-09-22,DQN noop,8422.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-11-20,DDQN (tuned) noop,7920.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-11-20,Duel hs,8051.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-11-20,Duel noop,11451.9,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-12-08,DDQN (tuned) hs,6796.1,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2015-12-08,Prior+Duel hs,7658.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2016-01-06,Prior hs,6872.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2016-01-06,Prior noop,9728,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2016-02-24,DDQN+Pop-Art noop,9745.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2016-04-05,Prior+Duel noop,10374.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2016-04-10,A3C FF hs,5560,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2016-04-10,A3C LSTM hs,5911.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2016-04-10,A3C FF (1 day) hs,8066.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2017-03-10,ES FF (1 hour) noop,8647.2,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Krull,Raw Score,2017-07-21,C51 noop,9735,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2012-07-14,SARSA,29151,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2012-07-19,Best linear,19544,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-02-26,Nature DQN,23270,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-07-15,Gorila,20620,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-09-22,DQN hs,20882,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-09-22,DQN noop,26059,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-11-20,Duel hs,24288,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-11-20,DDQN (tuned) noop,29710,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-11-20,Duel noop,34294,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-12-08,DDQN (tuned) hs,30207,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2015-12-08,Prior+Duel hs,37484,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2016-01-06,Prior hs,31676,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2016-01-06,Prior noop,39581,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2016-02-24,DDQN+Pop-Art noop,34393,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2016-04-05,Prior+Duel noop,48375,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2016-04-10,A3C FF (1 day) hs,3046,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2016-04-10,A3C FF hs,28819,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2016-04-10,A3C LSTM hs,40835,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Kung-Fu Master,Raw Score,2017-07-21,C51 noop,48192,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2012-07-14,SARSA,259,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2012-07-19,Best linear,10.7,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-02-26,Nature DQN,0,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-07-15,Gorila,84,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-09-10,MP-EB,142,Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-09-22,DQN noop,0,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-09-22,DQN hs,47,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-11-20,DDQN (tuned) noop,0,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-11-20,Duel noop,0,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-11-20,Duel hs,22,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-12-08,Prior+Duel hs,24,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2015-12-08,DDQN (tuned) hs,42,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-01-06,Prior noop,0,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-01-06,Prior hs,51,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-02-24,DDQN+Pop-Art noop,0,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-04-05,Prior+Duel noop,0,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-04-10,A3C LSTM hs,41,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-04-10,A3C FF (1 day) hs,53,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-04-10,A3C FF hs,67,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-08-22,A3C-CTS,273.7,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-08-22,DDQN-PC,3459,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2016-12-13,TRPO-hash,75,Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2017-03-03,DQN-CTS,0,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2017-03-03,DQN-PixelCNN,3705.5,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2017-03-10,ES FF (1 hour) noop,0,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2017-06-25,Sarsa-ε,399.5,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2017-06-25,Sarsa-φ-EB,2745.4,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2017-07-21,C51 noop,0,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Montezuma's Revenge,Raw Score,2012-07-14,SARSA,1227,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2012-07-19,Best linear,1692,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-02-26,Nature DQN,2311,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-07-15,Gorila,1263,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-09-22,DQN hs,1092.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-09-22,DQN noop,3085.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-11-20,Duel hs,2250.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-11-20,DDQN (tuned) noop,2711.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-11-20,Duel noop,6283.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-12-08,Prior+Duel hs,1007.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2015-12-08,DDQN (tuned) hs,1241.3,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2016-01-06,Prior hs,1865.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2016-01-06,Prior noop,6518.7,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2016-02-24,DDQN+Pop-Art noop,4963.8,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2016-04-05,Prior+Duel noop,3327.3,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2016-04-10,A3C FF (1 day) hs,594.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2016-04-10,A3C FF hs,653.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2016-04-10,A3C LSTM hs,850.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Ms. Pacman,Raw Score,2017-07-21,C51 noop,3415,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2012-07-14,SARSA,2247,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2012-07-19,Best linear,2500,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-02-26,Nature DQN,7257,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-07-15,Gorila,9238.5,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-09-22,DQN hs,6738.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-09-22,DQN noop,8207.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-11-20,DDQN (tuned) noop,10616,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-11-20,Duel hs,11185.1,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-11-20,Duel noop,11971.1,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-12-08,DDQN (tuned) hs,8960.3,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2015-12-08,Prior+Duel hs,13637.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2016-01-06,Prior hs,10497.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2016-01-06,Prior noop,12270.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2016-02-24,DDQN+Pop-Art noop,15851.2,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2016-04-05,Prior+Duel noop,15572.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2016-04-10,A3C FF (1 day) hs,5614,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2016-04-10,A3C FF hs,10476.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2016-04-10,A3C LSTM hs,12093.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2017-03-10,ES FF (1 hour) noop,4503,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Name This Game,Raw Score,2017-07-21,C51 noop,12542,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2015-09-22,DQN hs,7484.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2015-09-22,DQN noop,8485.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2015-11-20,DDQN (tuned) noop,12252.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2015-11-20,Duel hs,20410.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2015-11-20,Duel noop,23092.2,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2015-12-08,DDQN (tuned) hs,12366.5,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2015-12-08,Prior+Duel hs,63597,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2016-01-06,Prior hs,16903.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2016-01-06,Prior noop,18992.7,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2016-02-24,DDQN+Pop-Art noop,6202.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2016-04-05,Prior+Duel noop,70324.3,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2016-04-10,A3C FF (1 day) hs,28181.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2016-04-10,A3C FF hs,52894.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2016-04-10,A3C LSTM hs,74786.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2017-03-10,ES FF (1 hour) noop,4041,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Phoenix,Raw Score,2017-07-21,C51 noop,17490,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pit Fall,Raw Score,2016-04-10,A3C LSTM hs,-135.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pit Fall,Raw Score,2016-04-10,A3C FF (1 day) hs,-123,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pit Fall,Raw Score,2016-04-10,A3C FF hs,-78.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pit Fall,Raw Score,2017-03-10,ES FF (1 hour) noop,0,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2015-09-22,DQN noop,-286.1,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2015-09-22,DQN hs,-113.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2015-11-20,Duel hs,-46.9,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2015-11-20,DDQN (tuned) noop,-29.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2015-11-20,Duel noop,0,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2015-12-08,Prior+Duel hs,-243.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2015-12-08,DDQN (tuned) hs,-186.7,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2016-01-06,Prior hs,-427,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2016-01-06,Prior noop,-356.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2016-02-24,DDQN+Pop-Art noop,-2.6,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2016-04-05,Prior+Duel noop,0,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2016-08-22,A3C-CTS,-259.09,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2017-03-03,DQN-CTS,0,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2017-03-03,DQN-PixelCNN,0,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pitfall!,Raw Score,2017-07-21,C51 noop,0,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2012-07-14,SARSA,-17.4,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2012-07-19,Best linear,-19,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2013-12-19,DQN best,21,Playing Atari with Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-02-26,Nature DQN,18.9,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-07-15,Gorila,16.7,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-09-22,DQN hs,18,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-09-22,DQN noop,19.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-11-20,Duel hs,18.8,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-11-20,DDQN (tuned) noop,20.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-11-20,Duel noop,21,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-12-08,Prior+Duel hs,18.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2015-12-08,DDQN (tuned) hs,19.1,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2016-01-06,Prior hs,18.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2016-01-06,Prior noop,20.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2016-02-24,DDQN+Pop-Art noop,20.6,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2016-04-05,Prior+Duel noop,20.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2016-04-10,A3C FF hs,5.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2016-04-10,A3C LSTM hs,10.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2016-04-10,A3C FF (1 day) hs,11.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2017-03-10,ES FF (1 hour) noop,21,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Pong,Raw Score,2017-07-21,C51 noop,20.9,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2012-07-14,SARSA,86,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2012-07-19,Best linear,684.3,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-02-26,Nature DQN,1788,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-07-15,Gorila,2598.6,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-09-22,DQN noop,146.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-09-22,DQN hs,207.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-11-20,Duel noop,103,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-11-20,DDQN (tuned) noop,129.7,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-11-20,Duel hs,292.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-12-08,DDQN (tuned) hs,-575.5,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2015-12-08,Prior+Duel hs,1277.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-01-06,Prior noop,200,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-01-06,Prior hs,670.7,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-02-24,DDQN+Pop-Art noop,286.7,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-04-05,Prior+Duel noop,206,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-04-10,A3C FF (1 day) hs,194.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-04-10,A3C FF hs,206.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-04-10,A3C LSTM hs,421.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2016-08-22,A3C-CTS,99.32,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2017-03-03,DQN-CTS,206,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2017-03-03,DQN-PixelCNN,8358.7,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2017-03-10,ES FF (1 hour) noop,100,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Private Eye,Raw Score,2017-07-21,C51 noop,15095,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2012-07-14,SARSA,960.3,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2012-07-19,Best linear,613.5,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2013-12-19,DQN best,4500,Playing Atari with Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-02-26,Nature DQN,10596,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-07-15,Gorila,7089.8,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-09-10,MP-EB,15805,Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-09-22,DQN hs,9271.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-09-22,DQN noop,13117.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-11-20,Duel hs,14175.8,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-11-20,DDQN (tuned) noop,15088.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-11-20,Duel noop,19220.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-12-08,DDQN (tuned) hs,11020.8,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2015-12-08,Prior+Duel hs,14063,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2016-01-06,Prior hs,9944,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2016-01-06,Prior noop,16256.5,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2016-02-24,DDQN+Pop-Art noop,5236.8,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2016-04-05,Prior+Duel noop,18760.3,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2016-04-10,A3C FF (1 day) hs,13752.3,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2016-04-10,A3C FF hs,15148.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2016-04-10,A3C LSTM hs,21307.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2017-03-10,ES FF (1 hour) noop,147.5,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2017-06-25,Sarsa-ε,3895.3,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2017-06-25,Sarsa-φ-EB,4111.8,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Q*Bert,Raw Score,2017-07-21,C51 noop,23784,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2012-07-14,SARSA,2650,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2012-07-19,Best linear,1904,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-02-26,Nature DQN,8316,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-07-15,Gorila,5310.3,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-09-22,DQN hs,4748.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-09-22,DQN noop,7377.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-11-20,DDQN (tuned) noop,14884.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-11-20,Duel hs,16569.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-11-20,Duel noop,21162.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-12-08,DDQN (tuned) hs,10838.4,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2015-12-08,Prior+Duel hs,16496.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2016-01-06,Prior hs,11807.2,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2016-01-06,Prior noop,14522.3,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2016-02-24,DDQN+Pop-Art noop,12530.8,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2016-04-05,Prior+Duel noop,20607.6,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2016-04-10,A3C LSTM hs,6591.9,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2016-04-10,A3C FF (1 day) hs,10001.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2016-04-10,A3C FF hs,12201.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2017-03-10,ES FF (1 hour) noop,5009,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 River Raid,Raw Score,2017-07-21,C51 noop,17322,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2012-07-14,SARSA,89.1,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2012-07-19,Best linear,67.7,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-02-26,Nature DQN,18257,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-07-15,Gorila,43079.8,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-09-22,DQN hs,35215,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-09-22,DQN noop,39544,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-11-20,DDQN (tuned) noop,44127,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-11-20,Duel hs,58549,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-11-20,Duel noop,69524,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-12-08,DDQN (tuned) hs,43156,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2015-12-08,Prior+Duel hs,54630,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2016-01-06,Prior hs,52264,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2016-01-06,Prior noop,57608,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2016-02-24,DDQN+Pop-Art noop,47770,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2016-04-05,Prior+Duel noop,62151,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2016-04-10,A3C FF (1 day) hs,31769,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2016-04-10,A3C FF hs,34216,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2016-04-10,A3C LSTM hs,73949,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2017-03-10,ES FF (1 hour) noop,16590,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Road Runner,Raw Score,2017-07-21,C51 noop,55839,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2012-07-14,SARSA,12.4,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2012-07-19,Best linear,28.7,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-02-26,Nature DQN,51.6,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-07-15,Gorila,61.8,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-09-22,DQN hs,58.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-09-22,DQN noop,63.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-11-20,Duel hs,62,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-11-20,DDQN (tuned) noop,65.1,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-11-20,Duel noop,65.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-12-08,Prior+Duel hs,24.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2015-12-08,DDQN (tuned) hs,59.1,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2016-01-06,Prior hs,56.2,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2016-01-06,Prior noop,62.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2016-02-24,DDQN+Pop-Art noop,64.3,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2016-04-05,Prior+Duel noop,27.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2016-04-10,A3C FF (1 day) hs,2.3,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2016-04-10,A3C LSTM hs,2.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2016-04-10,A3C FF hs,32.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2017-03-10,ES FF (1 hour) noop,11.9,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Robotank,Raw Score,2017-07-21,C51 noop,52.3,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2012-07-14,SARSA,675.5,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2012-07-19,Best linear,664.8,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2013-12-19,DQN best,1740,Playing Atari with Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-02-26,Nature DQN,5286,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-07-15,Gorila,10145.9,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-09-22,DQN hs,4216.7,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-09-22,DQN noop,5860.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-11-20,DDQN (tuned) noop,16452.7,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-11-20,Duel hs,37361.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-11-20,Duel noop,50254.2,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-12-08,Prior+Duel hs,1431.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2015-12-08,DDQN (tuned) hs,14498,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2016-01-06,Prior hs,25463.7,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2016-01-06,Prior noop,26357.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2016-02-24,DDQN+Pop-Art noop,10932.3,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2016-04-05,Prior+Duel noop,931.6,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2016-04-10,A3C LSTM hs,1326.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2016-04-10,A3C FF (1 day) hs,2300.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2016-04-10,A3C FF hs,2355.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2017-03-10,ES FF (1 hour) noop,1390,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Seaquest,Raw Score,2017-07-21,C51 noop,266434,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2015-09-22,DQN noop,-13062.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2015-09-22,DQN hs,-12142.1,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2015-11-20,Duel hs,-11928,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2015-11-20,DDQN (tuned) noop,-9021.8,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2015-11-20,Duel noop,-8857.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2015-12-08,Prior+Duel hs,-18955.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2015-12-08,DDQN (tuned) hs,-11490.4,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2016-01-06,Prior hs,-10169.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2016-01-06,Prior noop,-9996.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2016-02-24,DDQN+Pop-Art noop,-13585.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2016-04-05,Prior+Duel noop,-19949.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2016-04-10,A3C LSTM hs,-14863.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2016-04-10,A3C FF (1 day) hs,-13700,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2016-04-10,A3C FF hs,-10911.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2017-03-10,ES FF (1 hour) noop,-15442.5,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Skiing,Raw Score,2017-07-21,C51 noop,-13901,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2015-09-22,DQN hs,1295.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2015-09-22,DQN noop,3482.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2015-11-20,Duel hs,1768.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2015-11-20,Duel noop,2250.8,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2015-11-20,DDQN (tuned) noop,3067.8,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2015-12-08,Prior+Duel hs,280.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2015-12-08,DDQN (tuned) hs,810,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-01-06,Prior hs,2272.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-01-06,Prior noop,4309,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-02-24,DDQN+Pop-Art noop,4544.8,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-04-05,Prior+Duel noop,133.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-04-10,A3C FF (1 day) hs,1884.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-04-10,A3C LSTM hs,1936.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-04-10,A3C FF hs,1956,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2016-08-22,A3C-CTS,2270.15,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2017-03-03,DQN-CTS,133.4,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2017-03-03,DQN-PixelCNN,2863.6,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2017-03-10,ES FF (1 hour) noop,2090,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Solaris,Raw Score,2017-07-21,C51 noop,8342,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2012-07-14,SARSA,267.9,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2012-07-19,Best linear,250.1,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2013-12-19,DQN best,1075,Playing Atari with Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-02-26,Nature DQN,1976,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-07-15,Gorila,1183.3,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-09-22,DQN hs,1293.8,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-09-22,DQN noop,1692.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-11-20,DDQN (tuned) noop,2525.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-11-20,Duel hs,5993.1,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-11-20,Duel noop,6427.3,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-12-08,DDQN (tuned) hs,2628.7,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2015-12-08,Prior+Duel hs,8978,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2016-01-06,Prior noop,2865.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2016-01-06,Prior hs,3912.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2016-02-24,DDQN+Pop-Art noop,2589.7,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2016-04-05,Prior+Duel noop,15311.5,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2016-04-10,A3C FF (1 day) hs,2214.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2016-04-10,A3C FF hs,15730.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2016-04-10,A3C LSTM hs,23846,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2017-03-10,ES FF (1 hour) noop,678.5,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Space Invaders,Raw Score,2017-07-21,C51 noop,5747,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2012-07-14,SARSA,9.4,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2012-07-19,Best linear,1070,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-02-26,Nature DQN,57997,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-07-15,Gorila,14919.2,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-09-22,DQN hs,52970,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-09-22,DQN noop,54282,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-11-20,DDQN (tuned) noop,60142,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-11-20,Duel noop,89238,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-11-20,Duel hs,90804,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-12-08,DDQN (tuned) hs,58365,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2015-12-08,Prior+Duel hs,127073,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2016-01-06,Prior hs,61582,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2016-01-06,Prior noop,63302,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2016-02-24,DDQN+Pop-Art noop,589,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2016-04-05,Prior+Duel noop,125117,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2016-04-10,A3C FF (1 day) hs,64393,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2016-04-10,A3C FF hs,138218,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2016-04-10,A3C LSTM hs,164766,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2017-03-10,ES FF (1 hour) noop,1470,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Star Gunner,Raw Score,2017-07-21,C51 noop,49095,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2015-09-22,DQN hs,-6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2015-09-22,DQN noop,-5.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2015-11-20,DDQN (tuned) noop,-2.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2015-11-20,Duel hs,4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2015-11-20,Duel noop,4.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2015-12-08,Prior+Duel hs,-0.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2015-12-08,DDQN (tuned) hs,1.9,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2016-01-06,Prior hs,5.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2016-01-06,Prior noop,8.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2016-02-24,DDQN+Pop-Art noop,-2.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2016-04-05,Prior+Duel noop,1.2,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2016-04-10,A3C FF hs,-9.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2016-04-10,A3C FF (1 day) hs,-9.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2016-04-10,A3C LSTM hs,-8.3,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Surround,Raw Score,2017-07-21,C51 noop,6.8,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2012-07-14,SARSA,0,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2012-07-19,Best linear,-0.1,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-02-26,Nature DQN,-2.5,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-07-15,Gorila,-0.7,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-09-22,DQN hs,11.1,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-09-22,DQN noop,12.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-11-20,DDQN (tuned) noop,-22.8,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-11-20,Duel hs,4.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-11-20,Duel noop,5.1,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-12-08,Prior+Duel hs,-13.2,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2015-12-08,DDQN (tuned) hs,-7.8,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2016-01-06,Prior hs,-5.3,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2016-01-06,Prior noop,0,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2016-02-24,DDQN+Pop-Art noop,12.1,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2016-04-05,Prior+Duel noop,0,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2016-04-10,A3C FF (1 day) hs,-10.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2016-04-10,A3C LSTM hs,-6.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2016-04-10,A3C FF hs,-6.3,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2017-03-10,ES FF (1 hour) noop,-4.5,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tennis,Raw Score,2017-07-21,C51 noop,23.1,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2012-07-14,SARSA,24.9,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2012-07-19,Best linear,3741,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-02-26,Nature DQN,5947,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-07-15,Gorila,8267.8,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-09-22,DQN hs,4786,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-09-22,DQN noop,4870,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-11-20,Duel hs,6601,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-11-20,DDQN (tuned) noop,8339,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-11-20,Duel noop,11666,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-12-08,Prior+Duel hs,4871,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2015-12-08,DDQN (tuned) hs,6608,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2016-01-06,Prior hs,5963,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2016-01-06,Prior noop,9197,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2016-02-24,DDQN+Pop-Art noop,4870,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2016-04-05,Prior+Duel noop,7553,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2016-04-10,A3C FF (1 day) hs,5825,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2016-04-10,A3C FF hs,12679,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2016-04-10,A3C LSTM hs,27202,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2017-03-10,ES FF (1 hour) noop,4970,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Time Pilot,Raw Score,2017-07-21,C51 noop,8329,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2012-07-14,SARSA,98.2,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2012-07-19,Best linear,114.3,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-02-26,Nature DQN,186.7,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-07-15,Gorila,118.5,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-09-22,DQN hs,45.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-09-22,DQN noop,68.1,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-11-20,Duel hs,48,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-11-20,Duel noop,211.4,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-11-20,DDQN (tuned) noop,218.4,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-12-08,DDQN (tuned) hs,92.2,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2015-12-08,Prior+Duel hs,108.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2016-01-06,Prior hs,56.9,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2016-01-06,Prior noop,204.6,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2016-02-24,DDQN+Pop-Art noop,183.9,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2016-04-05,Prior+Duel noop,245.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2016-04-10,A3C FF (1 day) hs,26.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2016-04-10,A3C LSTM hs,144.2,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2016-04-10,A3C FF hs,156.3,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2017-03-10,ES FF (1 hour) noop,130.3,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Tutankham,Raw Score,2017-07-21,C51 noop,280,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2012-07-14,SARSA,2449,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2012-07-19,Best linear,3533,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-02-26,Nature DQN,8456,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-07-15,Gorila,8747.7,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-09-22,DQN hs,8038.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-09-22,DQN noop,9989.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-11-20,DDQN (tuned) noop,22972.2,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-11-20,Duel hs,24759.2,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-11-20,Duel noop,44939.6,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-12-08,DDQN (tuned) hs,19086.9,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2015-12-08,Prior+Duel hs,22681.3,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2016-01-06,Prior hs,12157.4,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2016-01-06,Prior noop,16154.1,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2016-02-24,DDQN+Pop-Art noop,22474.4,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2016-04-05,Prior+Duel noop,33879.1,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2016-04-10,A3C FF (1 day) hs,54525.4,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2016-04-10,A3C FF hs,74705.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2016-04-10,A3C LSTM hs,105728.7,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2017-03-10,ES FF (1 hour) noop,67974,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Up and Down,Raw Score,2017-07-21,C51 noop,15612,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2012-07-14,SARSA,0.6,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2012-07-19,Best linear,66,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-02-26,Nature DQN,380,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-07-15,Gorila,523.4,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-09-10,MP-EB,0,Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-09-22,DQN hs,136,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-09-22,DQN noop,163,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-11-20,DDQN (tuned) noop,98,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-11-20,Duel hs,200,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-11-20,Duel noop,497,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-12-08,DDQN (tuned) hs,21,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2015-12-08,Prior+Duel hs,29,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-01-06,Prior noop,54,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-01-06,Prior hs,94,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-02-24,DDQN+Pop-Art noop,1172,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-04-05,Prior+Duel noop,48,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-04-10,A3C FF (1 day) hs,19,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-04-10,A3C FF hs,23,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-04-10,A3C LSTM hs,25,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-08-22,A3C-CTS,0,Unifying Count-Based Exploration and Intrinsic Motivation
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2016-12-13,TRPO-hash,445,Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2017-03-03,DQN-CTS,48,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2017-03-03,DQN-PixelCNN,82.2,Count-Based Exploration with Neural Density Models
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2017-03-10,ES FF (1 hour) noop,760,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2017-06-25,Sarsa-ε,0,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2017-06-25,Sarsa-φ-EB,1169.2,Count-Based Exploration in Feature Space for Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Venture,Raw Score,2017-07-21,C51 noop,1520,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2012-07-14,SARSA,19761,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2012-07-19,Best linear,16871,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-02-26,Nature DQN,42684,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-07-15,Gorila,112093.4,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-09-22,DQN hs,154414.1,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-09-22,DQN noop,196760.4,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-11-20,Duel noop,98209.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-11-20,Duel hs,110976.2,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-11-20,DDQN (tuned) noop,309941.9,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-12-08,DDQN (tuned) hs,367823.7,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2015-12-08,Prior+Duel hs,447408.6,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2016-01-06,Prior noop,282007.3,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2016-01-06,Prior hs,295972.8,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2016-02-24,DDQN+Pop-Art noop,56287,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2016-04-05,Prior+Duel noop,479197,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2016-04-10,A3C FF (1 day) hs,185852.6,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2016-04-10,A3C FF hs,331628.1,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2016-04-10,A3C LSTM hs,470310.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2017-03-10,ES FF (1 hour) noop,22834.8,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Video Pinball,Raw Score,2017-07-21,C51 noop,949604,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2012-07-14,SARSA,36.9,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2012-07-19,Best linear,1981,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-02-26,Nature DQN,3393,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-07-15,Gorila,10431,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-09-22,DQN hs,1609,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-09-22,DQN noop,2704,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-11-20,Duel hs,7054,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-11-20,DDQN (tuned) noop,7492,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-11-20,Duel noop,7855,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-12-08,DDQN (tuned) hs,6201,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2015-12-08,Prior+Duel hs,10471,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2016-01-06,Prior noop,4802,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2016-01-06,Prior hs,5727,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2016-02-24,DDQN+Pop-Art noop,483,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2016-04-05,Prior+Duel noop,12352,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2016-04-10,A3C FF (1 day) hs,5278,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2016-04-10,A3C FF hs,17244,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2016-04-10,A3C LSTM hs,18082,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2017-03-10,ES FF (1 hour) noop,3480,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Wizard of Wor,Raw Score,2017-07-21,C51 noop,9300,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2015-09-22,DQN hs,4577.5,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2015-09-22,DQN noop,18098.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2015-11-20,DDQN (tuned) noop,11712.6,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2015-11-20,Duel hs,25976.5,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2015-11-20,Duel noop,49622.1,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2015-12-08,DDQN (tuned) hs,6270.6,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2015-12-08,Prior+Duel hs,58145.9,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2016-01-06,Prior hs,4687.4,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2016-01-06,Prior noop,11357,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2016-02-24,DDQN+Pop-Art noop,21409.5,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2016-04-05,Prior+Duel noop,69618.1,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2016-04-10,A3C LSTM hs,5615.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2016-04-10,A3C FF hs,7157.5,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2016-04-10,A3C FF (1 day) hs,7270.8,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2017-03-10,ES FF (1 hour) noop,16401.7,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Yars Revenge,Raw Score,2017-07-21,C51 noop,35050,A Distributional Perspective on Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2012-07-14,SARSA,21.4,Investigating Contingency Awareness Using Atari 2600 Games
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2012-07-19,Best linear,3365,The Arcade Learning Environment: An Evaluation Platform for General Agents
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-02-26,Nature DQN,4977,Human-level control through deep reinforcement learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-07-15,Gorila,6159.4,Massively Parallel Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-09-22,DQN hs,4412,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-09-22,DQN noop,5363,Deep Reinforcement Learning with Double Q-learning (algorithm from Human-level control through deep reinforcement learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-11-20,DDQN (tuned) noop,10163,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Deep Reinforcement Learning with Double Q-learning)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-11-20,Duel hs,10164,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-11-20,Duel noop,12944,Dueling Network Architectures for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-12-08,DDQN (tuned) hs,8593,Deep Reinforcement Learning with Double Q-learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2015-12-08,Prior+Duel hs,11320,Deep Reinforcement Learning with Double Q-learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2016-01-06,Prior hs,9474,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2016-01-06,Prior noop,10469,Prioritized Experience Replay
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2016-02-24,DDQN+Pop-Art noop,14402,Learning functions across many orders of magnitudes
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2016-04-05,Prior+Duel noop,13886,Dueling Network Architectures for Deep Reinforcement Learning (algorithm from Prioritized Experience Replay)
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2016-04-10,A3C FF (1 day) hs,2659,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2016-04-10,A3C LSTM hs,23519,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2016-04-10,A3C FF hs,24622,Asynchronous Methods for Deep Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2017-03-10,ES FF (1 hour) noop,6380,Evolution Strategies as a Scalable Alternative to Reinforcement Learning
Real-Time Video Games,Game Playing,Real-Time Video Games,Atari,Atari 2600 Zaxxon,Raw Score,2017-07-21,C51 noop,10513,A Distributional Perspective on Reinforcement Learning
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2011-08-31,CD-DNN,16.1,https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CD-DNN-HMM-SWB-Interspeech2011-Pub.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2012-04-27,DNN-HMM,18.5,https://pdfs.semanticscholar.org/ce25/00257fda92338ec0a117bea1dbc0381d7c73.pdf?_ga=1.195375081.452266805.1483390947
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2013-08-23,CNN,11.5,http://www.cs.toronto.edu/~asamir/papers/icassp13_cnn.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2013-08-23,HMM-DNN +sMBR,12.6,http://www.danielpovey.com/files/2013_interspeech_dnn.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2013-08-25,DNN sMBR,12.6,http://www.danielpovey.com/files/2013_interspeech_dnn.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2013-08-25,DNN MMI,12.9,http://www.danielpovey.com/files/2013_interspeech_dnn.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2013-08-25,DNN MPE,12.9,http://www.danielpovey.com/files/2013_interspeech_dnn.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2013-08-25,DNN BMMI,12.9,http://www.danielpovey.com/files/2013_interspeech_dnn.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2014-06-23,DNN + Dropout,15,Building DNN Acoustic Models for Large Vocabulary Speech Recognition
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2014-06-30,DNN,16,Increasing Deep Neural Network Acoustic Model Size for Large Vocabulary Continuous Speech Recognition
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2014-08-23,CNN on MFSC/fbanks + 1 non-conv layer for FMLLR/I-Vectors concatenated in a DNN,10.4,http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p5609-soltau.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2014-12-07,Deep Speech + FSH,12.6,Deep Speech: Scaling up end-to-end speech recognition
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2014-12-07,Deep Speech,20,Deep Speech: Scaling up end-to-end speech recognition
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2014-12-23,"CNN + Bi-RNN + CTC (speech to letters), 25.9% WER if trainedonlyon SWB",12.6,Deep Speech: Scaling up end-to-end speech recognition
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2015-05-21,IBM 2015,8,The IBM 2015 English Conversational Telephone Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2015-08-23,HMM-TDNN + iVectors,11,http://speak.clsp.jhu.edu/uploads/publications/papers/1048_pdf.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2015-08-23,HMM-TDNN + pNorm + speed up/down speech,12.9,http://www.danielpovey.com/files/2015_interspeech_augmentation.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2015-09-23,"Deep CNN (10 conv, 4 FC layers), multi-scale feature maps",12.2,Very Deep Multilingual Convolutional Neural Networks for LVCSR
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2016-04-27,IBM 2016,6.9,The IBM 2016 English Conversational Telephone Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2016-06-23,"RNN + VGG + LSTM acoustic model trained on SWB+Fisher+CH, N-gram + ""model M"" + NNLM language model",6.6,The IBM 2016 English Conversational Telephone Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2016-09-23,"VGG/Resnet/LACE/BiLSTM acoustic model trained on SWB+Fisher+CH, N-gram + RNNLM language model trained on Switchboard+Fisher+Gigaword+Broadcast",6.3,The Microsoft 2016 Conversational Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2016-09-23,HMM-BLSTM trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher,8.5,http://www.danielpovey.com/files/2016_interspeech_mmi.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2016-09-23,HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher (10% / 15.1% respectively trained on SWBD only),9.2,http://www.danielpovey.com/files/2016_interspeech_mmi.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2016-10-17,CNN-LSTM,6.6,Achieving Human Parity in Conversational Speech Recognition
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2016-12-17,Microsoft 2016b,5.8,Achieving Human Parity in Conversational Speech Recognition
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2017-02-17,Microsoft 2016,6.2,The Microsoft 2016 Conversational Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2017-02-17,RNNLM,6.9,The Microsoft 2016 Conversational Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,Hub500,Word error rate on Switchboard trained against the Hub5'00 dataset,Percentage Error,2017-03-23,"ResNet + BiLSTMs acoustic model, with 40d FMLLR + i-Vector inputs, trained on SWB+Fisher+CH, n-gram + model-M + LSTM + Strided ( trous) convs-based LM trained on Switchboard+Fisher+Gigaword+Broadcast",5.5,English Conversational Telephone Speech Recognition by Humans and Machines
Speech Recognition,Speech Recognition,Speech Recognition,CHiMe,chime clean,Percentage Error,2014-12-23,CNN + Bi-RNN + CTC (speech to letters),6.3,Deep Speech: Scaling up end-to-end speech recognition
Speech Recognition,Speech Recognition,Speech Recognition,CHiMe,chime clean,Percentage Error,2015-12-23,"9-layer model w/ 2 layers of 2D-invariant convolution & 7 recurrent layers, w/ 68M parameters",3.34,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Speech Recognition,Speech Recognition,Speech Recognition,CHiMe,chime real,Percentage Error,2014-12-23,CNN + Bi-RNN + CTC (speech to letters),67.94,Deep Speech: Scaling up end-to-end speech recognition
Speech Recognition,Speech Recognition,Speech Recognition,CHiMe,chime real,Percentage Error,2015-12-23,"9-layer model w/ 2 layers of 2D-invariant convolution & 7 recurrent layers, w/ 68M parameters",21.79,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Speech Recognition,Speech Recognition,Speech Recognition,Fisher,fisher WER,Word Error Rate (WER),2016-09-23,HMM-BLSTMtrained with MMI + data augmentation (speed) + iVectors + 3 regularizations + SWBD,9.6,http://www.danielpovey.com/files/2016_interspeech_mmi.pdf
Speech Recognition,Speech Recognition,Speech Recognition,Fisher,fisher WER,Word Error Rate (WER),2016-09-23,HMM-TDNNtrained with MMI + data augmentation (speed) + iVectors + 3 regularizations + SWBD,9.8,http://www.danielpovey.com/files/2016_interspeech_mmi.pdf
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testclean,Word Error Rate (WER),2015-08-23,HMM-TDNN + iVectors,4.83,http://speak.clsp.jhu.edu/uploads/publications/papers/1048_pdf.pdf
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testclean,Word Error Rate (WER),2015-08-23,HMM-DNN + pNorm*,5.51,http://www.danielpovey.com/files/2015_icassp_librispeech.pdf
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testclean,Word Error Rate (WER),2015-08-23,HMM-(SAT)GMM,8.01,Kaldi ASR
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testclean,Word Error Rate (WER),2015-12-23,"9-layer model w/ 2 layers of 2D-invariant convolution & 7 recurrent layers, w/ 68M parameters trained on 11940h",5.33,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testclean,Word Error Rate (WER),2016-09-23,HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations,4.28,http://www.danielpovey.com/files/2016_interspeech_mmi.pdf
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testother,Word Error Rate (WER),2015-08-23,TDNN + pNorm + speed up/down speech,12.51,http://www.danielpovey.com/files/2015_interspeech_augmentation.pdf
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testother,Word Error Rate (WER),2015-08-23,HMM-DNN + pNorm*,13.97,http://www.danielpovey.com/files/2015_icassp_librispeech.pdf
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testother,Word Error Rate (WER),2015-08-23,HMM-(SAT)GMM,22.49,Kaldi ASR
Speech Recognition,Speech Recognition,Speech Recognition,librispeech,librispeech WER testother,Word Error Rate (WER),2015-12-23,"9-layer model w/ 2 layers of 2D-invariant convolution & 7 recurrent layers, w/ 68M parameters trained on 11940h",13.25,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2013-08-23,HMM-DNN +sMBR,18.4,http://www.danielpovey.com/files/2013_interspeech_dnn.pdf
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2014-06-23,DNN + Dropout,19.1,Building DNN Acoustic Models for Large Vocabulary Speech Recognition
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2014-12-23,"CNN + Bi-RNN + CTC (speech to letters), 25.9% WER if trainedonlyon SWB",16,Deep Speech: Scaling up end-to-end speech recognition
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2015-08-23,HMM-TDNN + iVectors,17.1,http://speak.clsp.jhu.edu/uploads/publications/papers/1048_pdf.pdf
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2015-08-23,HMM-TDNN + pNorm + speed up/down speech,19.3,http://www.danielpovey.com/files/2015_interspeech_augmentation.pdf
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2016-06-23,"RNN + VGG + LSTM acoustic model trained on SWB+Fisher+CH, N-gram + ""model M"" + NNLM language model",12.2,The IBM 2016 English Conversational Telephone Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2016-09-23,"VGG/Resnet/LACE/BiLSTM acoustic model trained on SWB+Fisher+CH, N-gram + RNNLM language model trained on Switchboard+Fisher+Gigaword+Broadcast",11.9,The Microsoft 2016 Conversational Speech Recognition System
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2016-09-23,HMM-BLSTM trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher,13,http://www.danielpovey.com/files/2016_interspeech_mmi.pdf
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2016-09-23,HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher (10% / 15.1% respectively trained on SWBD only),13.3,http://www.danielpovey.com/files/2016_interspeech_mmi.pdf
Speech Recognition,Speech Recognition,Speech Recognition,swb_hub_500,swb_hub_500 WER fullSWBCH,Word Error Rate (WER),2017-03-23,"ResNet + BiLSTMs acoustic model, with 40d FMLLR + i-Vector inputs, trained on SWB+Fisher+CH, n-gram + model-M + LSTM + Strided ( trous) convs-based LM trained on Switchboard+Fisher+Gigaword+Broadcast",10.3,English Conversational Telephone Speech Recognition by Humans and Machines
Speech Recognition,Speech Recognition,Speech Recognition,timit,timit PER,Percentage Error,2009-08-23,"(first, modern) HMM-DBN",23,http://www.cs.toronto.edu/~asamir/papers/NIPS09.pdf
Speech Recognition,Speech Recognition,Speech Recognition,timit,timit PER,Percentage Error,2013-03-23,Bi-LSTM + skip connections w/ CTC,17.7,Speech Recognition with Deep Recurrent Neural Networks
Speech Recognition,Speech Recognition,Speech Recognition,timit,timit PER,Percentage Error,2014-08-23,"CNN in time and frequency + dropout, 17.6% w/o dropout",16.7,http://www.inf.u-szeged.hu/~tothl/pubs/ICASSP2014.pdf
Speech Recognition,Speech Recognition,Speech Recognition,timit,timit PER,Percentage Error,2015-06-23,Bi-RNN + Attention,17.6,Attention-Based Models for Speech Recognition
Speech Recognition,Speech Recognition,Speech Recognition,timit,timit PER,Percentage Error,2015-09-23,Hierarchical maxout CNN + Dropout,16.5,
Speech Recognition,Speech Recognition,Speech Recognition,timit,timit PER,Percentage Error,2016-03-23,RNN-CRF on 24(x3) MFSC,17.3,Segmental Recurrent Neural Networks for End-to-end Speech Recognition
Speech Recognition,Speech Recognition,Speech Recognition,wsj,wsj WER eval92,Word Error Rate (WER),2014-08-23,CNN over RAW speech (wav),5.6,http://infoscience.epfl.ch/record/203464/files/Palaz_Idiap-RR-18-2014.pdf
Speech Recognition,Speech Recognition,Speech Recognition,wsj,wsj WER eval92,Word Error Rate (WER),2015-04-23,TC-DNN-BLSTM-DNN,3.47,Deep Recurrent Neural Networks for Acoustic Modelling
Speech Recognition,Speech Recognition,Speech Recognition,wsj,wsj WER eval92,Word Error Rate (WER),2015-08-23,"test-set on open vocabulary (i.e. harder), model = HMM-DNN + pNorm*",3.63,http://www.danielpovey.com/files/2015_icassp_librispeech.pdf
Speech Recognition,Speech Recognition,Speech Recognition,wsj,wsj WER eval92,Word Error Rate (WER),2015-12-23,"9-layer model w/ 2 layers of 2D-invariant convolution & 7 recurrent layers, w/ 68M parameters",3.6,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Speech Recognition,Speech Recognition,Speech Recognition,wsj,wsj WER eval93,Word Error Rate (WER),2015-08-23,"test-set on open vocabulary (i.e. harder), model = HMM-DNN + pNorm*",5.66,http://www.danielpovey.com/files/2015_icassp_librispeech.pdf
Speech Recognition,Speech Recognition,Speech Recognition,wsj,wsj WER eval93,Word Error Rate (WER),2015-12-23,"9-layer model w/ 2 layers of 2D-invariant convolution & 7 recurrent layers, w/ 68M parameters",4.98,Deep Speech 2: End-to-End Speech Recognition in English and Mandarin
Instrumental-Track Recognition,Music Information Retrieval,Instrumentals Recognition,SATIN,Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017),Percentage Correct,2013-10-17,Ghosal et al.,17.3,A hierarchical approach for speech-instrumental-song classification | SpringerLink
Instrumental-Track Recognition,Music Information Retrieval,Instrumentals Recognition,SATIN,Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017),Percentage Correct,2014-09-30,SVMBFF,12.5,On Evaluation Validity in Music Autotagging
Instrumental-Track Recognition,Music Information Retrieval,Instrumentals Recognition,SATIN,Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017),Percentage Correct,2014-09-30,VQMM,29.8,On Evaluation Validity in Music Autotagging
Instrumental-Track Recognition,Music Information Retrieval,Instrumentals Recognition,SATIN,Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017),Percentage Correct,2017-06-23,Bayle et al.,82.5,Revisiting Autotagging Toward Faultless Instrumental Playlists Generation
Image Generation,Image Generation,Image Generation,CIFAR-10,Generative models of CIFAR-10 images,Model Entropy,2014-10-30,NICE,4.48,NICE: Non-linear Independent Components Estimation
Image Generation,Image Generation,Image Generation,CIFAR-10,Generative models of CIFAR-10 images,Model Entropy,2015-02-16,DRAW,4.13,DRAW: A Recurrent Neural Network For Image Generation
Image Generation,Image Generation,Image Generation,CIFAR-10,Generative models of CIFAR-10 images,Model Entropy,2016-05-27,Real NVP,3.49,Density estimation using Real NVP
Image Generation,Image Generation,Image Generation,CIFAR-10,Generative models of CIFAR-10 images,Model Entropy,2016-05-27,PixelRNN,3,Density estimation using Real NVP
Image Generation,Image Generation,Image Generation,CIFAR-10,Generative models of CIFAR-10 images,Model Entropy,2016-06-15,VAE with IAF,3.11,Improved Variational Inference with Inverse Autoregressive Flow
Image Generation,Image Generation,Image Generation,CIFAR-10,Generative models of CIFAR-10 images,Model Entropy,2016-11-04,PixelCNN++,2.92,Forum | OpenReview (source code)
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2012-04-07,KN5+cache baseline,125.7,http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2012-04-07,KN5+RNNME ensemble,78.8,http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2012-07-27,RNNLM,124.7,https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2012-07-27,RNN-LDA LM,113.7,https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2012-07-27,RNN-LDA LM+KN5+cache,92,https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2012-07-27,RNN-LDA ensemble,80.1,https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2012-07-27,RNN-LDA+all,74.1,https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2013-12-20,Deep RNN,107.5,How to Construct Deep Recurrent Neural Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2014-09-08,RNN Dropout Regularization,68.7,Recurrent Neural Network Regularization
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2016-08-11,RHN,71.3,Recurrent Highway Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2016-09-26,Pointer Sentinel-LSTM,70.9,Pointer Sentinel Mixture Models
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2016-10-05,Variational LSTM,73.4,A Theoretically Grounded Application of Dropout in Recurrent Neural Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2016-10-27,RHN,68.5,Recurrent Highway Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2016-10-27,RHN+WT,66,Recurrent Highway Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2017-02-15,Neural Architecture Search,62.4,Neural Architecture Search with Reinforcement Learning
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Penn Treebank,Penn Treebank (Perplexity when parsing English sentences),Perplexity,2017-03-03,RHN+WT,65.4,Recurrent Highway Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2011-06-28,RNN,1.6,http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2013-08-04,"RNN, LSTM",1.67,Generating Sequences With Recurrent Neural Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2015-02-15,Gated Feedback RNN,1.58,Gated Feedback Recurrent Neural Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2015-07-06,Grid LSTM,1.47,Grid Long Short-Term Memory
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2016-07-12,Recurrent Highway Networks,1.32,Recurrent Highway Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2016-08-11,RHN,1.42,Recurrent Highway Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2016-09-06,Hierarchical Multiscale RNN,1.32,Hierarchical Multiscale Recurrent Neural Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2016-09-27,Hypernetworks,1.39,HyperNetworks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2016-10-19,Surprisal-Driven Feedback RNN,1.37,Surprisal-Driven Feedback in Recurrent Networks
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2016-10-31,Surprisal-Driven Zoneout,1.313,https://pdfs.semanticscholar.org/e9bc/83f9ff502bec9cffb750468f76fdfcf5dd05.pdf
Language Modeling,Language Modelling and Comprehension,Language Modelling and Comprehension,Hutter Prize,Hutter Prize (bits per character to encode English text),Model Entropy,2017-03-03,Large RHN depth 10,1.27,Recurrent Highway Networks
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2016-10-26,Stanford Reader,21.7,https://arxiv.org/abs/1610.08431v3
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2016-10-26,Modified Stanford,32.1,https://arxiv.org/abs/1610.08431v3
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2016-10-26,GA + feat.,49,https://arxiv.org/abs/1610.08431v3
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2016-10-26,AS + feat.,44.5,https://arxiv.org/abs/1610.08431v3
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2017-03-07,GA+MAGE (48),51.6,https://arxiv.org/abs/1703.02620v1
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2017-03-07,GA+MAGE(48),51.6,https://arxiv.org/abs/1703.02620v1
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2018-10-05,AttSum-Feat+L1,60.22,https://arxiv.org/abs/1810.02891
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2020-02-13,T-NLG,68,Turing-NLG: A 17-billion-parameter language model by Microsoft
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2020-07-22,GPT3 zero shot,76.2,Language Models are Few-Shot Learners
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2020-07-22,GPT3 one shot,72.5,Language Models are Few-Shot Learners
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2020-07-22,GPT3 few shot,86.4,Language Models are Few-Shot Learners
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2019-02-14,GPT2 (zero shot),63.4,Language Models are Unsupervised Multitask Learners
Reading Comprehension,Language Modelling and Comprehension,Language Modelling and Comprehension,LAMBADA,LAMBADA prediction of words in discourse,Percentage Correct,2019-09-19,Megatron-LM (zero shot),66.5,https://arxiv.org/abs/1909.08053v2
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-De BLEU,news-test-2014 En-De BLEU,BLEU,2014-02-24,PBMT,20.7,Edinburgh’s phrase-based machine translation systems for WMT-14
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-De BLEU,news-test-2014 En-De BLEU,BLEU,2016-07-14,NSE-NSE,17.93,Neural Semantic Encoders
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-De BLEU,news-test-2014 En-De BLEU,BLEU,2016-07-23,Deep-Att,20.7,Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-De BLEU,news-test-2014 En-De BLEU,BLEU,2016-09-26,GNMT+RL,26.3,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-De BLEU,news-test-2014 En-De BLEU,BLEU,2017-01-23,MoE 2048,26.03,Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-De BLEU,news-test-2014 En-De BLEU,BLEU,2017-05-12,ConvS2S ensemble,26.36,Convolutional Sequence to Sequence Learning
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2014-02-24,PBMT,37,Edinburgh’s phrase-based machine translation systems for WMT-14
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2014-09-01,RNN-search50*,36.15,Neural Machine Translation by Jointly Learning to Align and Translate
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2014-09-10,LSTM,34.81,Sequence to Sequence Learning with Neural Networks (algorithm from http://www.bioinf.jku.at/publications/older/2604.pdf)
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2014-09-10,SMT+LSTM5,36.5,Sequence to Sequence Learning with Neural Networks
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2014-10-30,LSTM6 + PosUnk,37.5,Addressing the Rare Word Problem in Neural Machine Translation
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2016-07-23,Deep-Att + PosUnk,39.2,Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2016-09-26,GNMT+RL,39.92,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2017-01-23,MoE 2048,40.56,Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
Translation,Language Modelling and Comprehension,Translation,news-test-2014 En-Fr BLEU,news-test-2014 En-Fr BLEU,BLEU,2017-05-12,ConvS2S ensemble,41.29,Convolutional Sequence to Sequence Learning
Translation,Language Modelling and Comprehension,Translation,news-test-2016 En-Ro BLEU,news-test-2016 En-Ro BLEU,BLEU,2016-07-11,GRU BPE90k,28.9,The QT21/HimL Combined Machine Translation System
Translation,Language Modelling and Comprehension,Translation,news-test-2016 En-Ro BLEU,news-test-2016 En-Ro BLEU,BLEU,2017-05-12,ConvS2S BPE40k,29.88,Convolutional Sequence to Sequence Learning
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2014-11-15,The Professor 2014,76.7,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2014-11-15,Tutor 2014,80.83,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2014-11-15,Uberbot 2014,81.67,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2014-11-15,Izar 2014,88.3,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2014-11-15,Misuku 2014,88.3,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2014-11-15,Rose 2014,89.2,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2015-09-19,Rose 2015,75,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2015-09-19,Izar 2015,76.7,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2015-09-19,Lisa 2015,80,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2015-09-19,Mitsuku 2015,83.3,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2016-09-17,Katie 2016,76.7,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2016-09-17,Rose 2016,77.5,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2016-09-17,Arckon 2016,77.5,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2016-09-17,Tutor 2016,78.3,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Translation,Language Modelling and Comprehension,Translation,,The Loebner Prize scored selection answers,Percentage Correct,2016-09-17,Mitsuku 2016,90,AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2015-06-10,Attentive reader,63,Teaching Machines to Read and Comprehend
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2015-06-10,Impatient reader,63.8,Teaching Machines to Read and Comprehend
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-03-04,AS reader (greedy),74.8,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-03-04,AS reader (avg),75.4,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-06-05,GA reader,77.4,Gated-Attention Readers for Text Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-06-07,EpiReader,74,Natural Language Comprehension with the EpiReader
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-06-07,AIA,75.7,Iterative Alternating Neural Attention for Machine Reading
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-08-04,AoA reader,74.4,Attention-over-Attention Neural Networks for Reading Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-08-08,Attentive+relabling+ensemble,77.6,A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-09-17,ReasoNet,74.7,ReasoNet: Learning to Stop Reading in Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-11-09,AIA,76.1,Iterative Alternating Neural Attention for Machine Reading
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2016-12-01,GA update L(w),77.9,Gated-Attention Readers for Text Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,CNN,CNN Comprehension test,Percentage Correct,2017-03-07,GA+MAGE (32),78.6,Linguistic Knowledge as Memory for Recurrent Neural Networks
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2015-06-10,Impatient reader,68,Teaching Machines to Read and Comprehend
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2015-06-10,Attentive reader,69,Teaching Machines to Read and Comprehend
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2016-03-04,AS reader (avg),77.1,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2016-03-04,AS reader (greedy),77.7,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2016-06-05,GA reader,78.1,Gated-Attention Readers for Text Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2016-08-08,Attentive+relabling+ensemble,79.2,A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2016-09-17,ReasoNet,76.6,ReasoNet: Learning to Stop Reading in Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,Daily Mail,Daily Mail Comprehension test,Percentage Correct,2016-12-01,GA update L(w),80.9,Gated-Attention Readers for Text Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-160-all,Reading comprehension MCTest-160-all,Percentage Correct,2013-10-01,SW+D+RTE,69.16,MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-160-all,Reading comprehension MCTest-160-all,Percentage Correct,2015-07-26,Narasimhan-model3,73.27,Machine Comprehension with Discourse Relations
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-160-all,Reading comprehension MCTest-160-all,Percentage Correct,2015-07-26,Wang-et-al,75.27,A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-160-all,Reading comprehension MCTest-160-all,Percentage Correct,2016-03-29,Parallel-Hierarchical,74.58,A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-500-all,Reading comprehension MCTest-500-all,Percentage Correct,2013-10-01,SW+D+RTE,63.33,MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-500-all,Reading comprehension MCTest-500-all,Percentage Correct,2015-07-26,Narasimhan-model3,63.75,Machine Comprehension with Discourse Relations
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-500-all,Reading comprehension MCTest-500-all,Percentage Correct,2015-07-26,LSSVM,67.83,Learning Answer-Entailing Structures for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-500-all,Reading comprehension MCTest-500-all,Percentage Correct,2015-07-26,Wang-et-al,69.94,A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,MCTest-500-all,Reading comprehension MCTest-500-all,Percentage Correct,2016-03-29,Parallel-Hierarchical,71,A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-11-04,Dynamic Coattention Networks (single model),66.233,Dynamic Coattention Networks For Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-11-04,Dynamic Coattention Networks (ensemble),71.625,Dynamic Coattention Networks For Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-11-07,Match-LSTM+Ans-Ptr,67.901,Machine Comprehension Using Match-LSTM and Answer Pointer
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-11-29,BiDAF (single model),68.478,Bidirectional Attention Flow for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-12-13,MPM (single model),70.387,Multi-Perspective Context Matching for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-12-13,MPM (ensemble),73.765,Multi-Perspective Context Matching for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-12-29,FastQA,68.436,Making Neural QA as Simple as Possible but not Simpler
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2016-12-29,FastQAExt,70.849,Making Neural QA as Simple as Possible but not Simpler
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-02-24,BiDAF (ensemble),73.744,Bidirectional Attention Flow for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-03-08,r-net (single model),74.614,https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-03-08,r-net (ensemble),76.922,https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-03-31,Document Reader (single model),70.733,Reading Wikipedia to Answer Open-Domain Questions
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-04-20,SEDT+BiDAF (single model),68.478,Structural Embedding of Syntactic Trees for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-04-20,SEDT+BiDAF (ensemble),73.723,Structural Embedding of Syntactic Trees for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-04-24,Ruminating Reader (single model),70.639,Ruminating Reader: Reasoning with Gated Multi-Hop Attention
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-05-08,Mnemonic reader (single model),69.863,Mnemonic Reader for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-05-08,Mnemonic reader (ensemble),73.754,Mnemonic Reader for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-05-31,jNet (single model),70.607,Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-05-31,RaSoR (single model),70.849,Learning Recurrent Span Representations for Extractive Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-05-31,jNet (ensemble),73.01,Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-06-20,ReasoNet ensemble,73.4,ReasoNet: Learning to Stop Reading in Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-07-28,MEMEN,75.37,MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-08-16,DCN+ (ensemble),78.706,The Stanford Question Answering Dataset
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-08-21,RMR (ensemble),77.678,Mnemonic Reader for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset EM test,EM,2017-09-20,AIR-FusionNet (ensemble),78.842,The Stanford Question Answering Dataset
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-11-04,Dynamic Coattention Networks (single model),75.896,Dynamic Coattention Networks For Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-11-04,Dynamic Coattention Networks (ensemble),80.383,Dynamic Coattention Networks For Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-11-07,Match-LSTM+Ans-Ptr,77.022,Machine Comprehension Using Match-LSTM and Answer Pointer
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-11-29,BiDAF (single model),77.971,Bidirectional Attention Flow for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-12-13,MPM (single model),78.784,Multi-Perspective Context Matching for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-12-13,MPM (ensemble),81.257,Multi-Perspective Context Matching for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-12-29,FastQA,77.07,Making Neural QA as Simple as Possible but not Simpler
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2016-12-29,FastQAExt,78.857,Making Neural QA as Simple as Possible but not Simpler
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-02-24,BiDAF (ensemble),81.525,Bidirectional Attention Flow for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-03-08,r-net (single model),82.458,https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-03-08,r-net (ensemble),84.006,https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-03-31,Document Reader (single model),79.353,Reading Wikipedia to Answer Open-Domain Questions
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-04-20,SEDT+BiDAF (single model),77.971,Structural Embedding of Syntactic Trees for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-04-20,SEDT+BiDAF (ensemble),81.53,Structural Embedding of Syntactic Trees for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-04-24,Ruminating Reader (single model),79.821,Ruminating Reader: Reasoning with Gated Multi-Hop Attention
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-05-08,Mnemonic reader (single model),79.207,Mnemonic Reader for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-05-08,Mnemonic reader (ensemble),81.863,Mnemonic Reader for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-05-31,RaSoR (single model),78.741,Learning Recurrent Span Representations for Extractive Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-05-31,jNet (single model),79.456,Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-05-31,jNet (ensemble),81.517,Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-06-20,ReasoNet ensemble,82.9,ReasoNet: Learning to Stop Reading in Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-07-28,MEMEN,82.66,MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-08-16,DCN+ (ensemble),85.619,The Stanford Question Answering Dataset
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-08-21,RMR (ensemble),84.888,Mnemonic Reader for Machine Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,SQUAD,Stanford Question Answering Dataset F1 test,F1,2017-09-20,AIR-FusionNet (ensemble),85.936,The Stanford Question Answering Dataset
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (10k training examples),Percentage Correct,2015-02-19,MemNN-AM+NG+NL (1k + strong supervision),93.3,Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (10k training examples),Percentage Correct,2015-03-31,MemN2N-PE+LS+RN,93.4,End-To-End Memory Networks
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (10k training examples),Percentage Correct,2016-01-05,DNC,96.2,https://www.gwern.net/docs/2016-graves.pdf
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (10k training examples),Percentage Correct,2016-06-30,DMN+,97.2,Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (10k training examples),Percentage Correct,2016-09-27,SDNC,97.1,Query-Reduction Networks for Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (10k training examples),Percentage Correct,2016-12-09,QRN,99.7,Query-Reduction Networks for Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (10k training examples),Percentage Correct,2016-12-12,EntNet,99.5,Tracking the World State with Recurrent Entity Networks
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (1k training examples),Percentage Correct,2015-03-31,MemN2N-PE+LS+RN,86.1,End-To-End Memory Networks
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (1k training examples),Percentage Correct,2015-06-24,DMN,93.6,Ask Me Anything: Dynamic Memory Networks for Natural Language Processing
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (1k training examples),Percentage Correct,2016-12-09,DMN+,66.8,Query-Reduction Networks for Question Answering (source code) (algorithm from Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes)
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (1k training examples),Percentage Correct,2016-12-09,QRN,90.1,Query-Reduction Networks for Question Answering
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (1k training examples),Percentage Correct,2016-12-12,EntNet,89.1,Tracking the World State with Recurrent Entity Networks
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi 20,bAbi 20 QA (1k training examples),Percentage Correct,2017-03-07,GA+MAGE (16),91.3,Linguistic Knowledge as Memory for Recurrent Neural Networks
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest CN,Percentage Correct,2016-03-04,AS reader (greedy),67.5,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest CN,Percentage Correct,2016-03-04,AS reader (avg),68.9,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest CN,Percentage Correct,2016-06-05,GA reader,69.4,Gated-Attention Readers for Text Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest CN,Percentage Correct,2016-06-07,EpiReader,67.4,Natural Language Comprehension with the EpiReader
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest CN,Percentage Correct,2016-08-04,AoA reader,69.4,Attention-over-Attention Neural Networks for Reading Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest CN,Percentage Correct,2016-12-01,"GA +feature, fix L(w)",70.7,Gated-Attention Readers for Text Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest CN,Percentage Correct,2016-12-01,NSE,71.9,Gated-Attention Readers for Text Comprehension (algorithm from Neural Semantic Encoders)
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-03-04,AS reader (avg),70.6,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-03-04,AS reader (greedy),71,Text Understanding with the Attention Sum Reader Network
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-06-05,GA reader,71.9,Gated-Attention Readers for Text Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-06-07,EpiReader,69.7,Natural Language Comprehension with the EpiReader
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-06-07,AIA,71,Iterative Alternating Neural Attention for Machine Reading
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-06-07,AIA,72,Iterative Alternating Neural Attention for Machine Reading
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-08-04,AoA reader,72,Attention-over-Attention Neural Networks for Reading Comprehension
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-12-01,NSE,73.2,Gated-Attention Readers for Text Comprehension (algorithm from Neural Semantic Encoders)
Reading Comprehension,Language Modelling and Comprehension,Reading Comprehension,bAbi Children's Book Test,bAbi Children's Book comprehension CBtest NE,Percentage Correct,2016-12-01,"GA +feature, fix L(w)",74.9,Gated-Attention Readers for Text Comprehension